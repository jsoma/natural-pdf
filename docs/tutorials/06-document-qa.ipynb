{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "442a55e6",
   "metadata": {},
   "source": [
    "# Document Question Answering (QA)\n",
    "\n",
    "Sometimes, instead of searching for specific text patterns, you just want to ask the document a question directly. `natural-pdf` includes an extractive Question Answering feature.\n",
    "\n",
    "\"Extractive\" means it finds the literal answer text within the document, rather than generating a new answer or summarizing.\n",
    "\n",
    "Let's ask our `01-practice.pdf` a few questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35493f4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T03:41:51.619116Z",
     "iopub.status.busy": "2025-06-16T03:41:51.618046Z",
     "iopub.status.idle": "2025-06-16T03:41:51.623668Z",
     "shell.execute_reply": "2025-06-16T03:41:51.622738Z"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install \"natural-pdf[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a42197b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T03:41:51.629038Z",
     "iopub.status.busy": "2025-06-16T03:41:51.628693Z",
     "iopub.status.idle": "2025-06-16T03:41:59.631763Z",
     "shell.execute_reply": "2025-06-16T03:41:59.631337Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soma/Development/natural-pdf/.nox/tutorials/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'February 3, 1905',\n",
       " 'confidence': 0.9979940056800842,\n",
       " 'start': 6,\n",
       " 'end': 6,\n",
       " 'found': True,\n",
       " 'page_num': 0,\n",
       " 'source_elements': <ElementCollection[TextElement](count=1)>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from natural_pdf import PDF\n",
    "\n",
    "# Load the PDF and get the page\n",
    "pdf = PDF(\"https://github.com/jsoma/natural-pdf/raw/refs/heads/main/pdfs/01-practice.pdf\")\n",
    "page = pdf.pages[0]\n",
    "\n",
    "# Ask about the date\n",
    "question_1 = \"What is the inspection date?\"\n",
    "answer_1 = page.ask(question_1)\n",
    "\n",
    "# The result is a dictionary with the answer, confidence, etc.\n",
    "answer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29bd2ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T03:41:59.633523Z",
     "iopub.status.busy": "2025-06-16T03:41:59.633183Z",
     "iopub.status.idle": "2025-06-16T03:42:00.365869Z",
     "shell.execute_reply": "2025-06-16T03:42:00.365477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Jungle Health and Safety Inspection Service',\n",
       " 'confidence': 0.9988948106765747,\n",
       " 'start': 0,\n",
       " 'end': 0,\n",
       " 'found': True,\n",
       " 'page_num': 0,\n",
       " 'source_elements': <ElementCollection[TextElement](count=1)>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask about the company name\n",
    "question_2 = \"What company was inspected?\"\n",
    "answer_2 = page.ask(question_2)\n",
    "\n",
    "# Display the answer dictionary\n",
    "answer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f99e4d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T03:42:00.368124Z",
     "iopub.status.busy": "2025-06-16T03:42:00.367909Z",
     "iopub.status.idle": "2025-06-16T03:42:01.107473Z",
     "shell.execute_reply": "2025-06-16T03:42:01.104874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Inadequate Protective Equipment.',\n",
       " 'confidence': 0.9997999668121338,\n",
       " 'start': 26,\n",
       " 'end': 26,\n",
       " 'found': True,\n",
       " 'page_num': 0,\n",
       " 'source_elements': <ElementCollection[TextElement](count=1)>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask about specific content from the table\n",
    "question_3 = \"What is statute 5.8.3 about?\"\n",
    "answer_3 = page.ask(question_3)\n",
    "\n",
    "# Display the answer\n",
    "answer_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99103ff4",
   "metadata": {},
   "source": [
    "The results include the extracted `answer`, a `confidence` score (useful for filtering uncertain answers), the `page_num`, and the `source_elements`.\n",
    "\n",
    "## Collecting Results into a DataFrame\n",
    "\n",
    "If you're asking multiple questions, it's often useful to collect the results into a pandas DataFrame for easier analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e77f39f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T03:42:01.115445Z",
     "iopub.status.busy": "2025-06-16T03:42:01.115022Z",
     "iopub.status.idle": "2025-06-16T03:42:04.510218Z",
     "shell.execute_reply": "2025-06-16T03:42:04.509692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the inspection date?</td>\n",
       "      <td>February 3, 1905</td>\n",
       "      <td>0.997994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What company was inspected?</td>\n",
       "      <td>Jungle Health and Safety Inspection Service</td>\n",
       "      <td>0.998895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is statute 5.8.3 about?</td>\n",
       "      <td>Inadequate Protective Equipment.</td>\n",
       "      <td>0.999800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many violations were there in total?</td>\n",
       "      <td>4.12.7</td>\n",
       "      <td>0.662557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   question  \\\n",
       "0              What is the inspection date?   \n",
       "1               What company was inspected?   \n",
       "2              What is statute 5.8.3 about?   \n",
       "3  How many violations were there in total?   \n",
       "\n",
       "                                        answer  confidence  \n",
       "0                             February 3, 1905    0.997994  \n",
       "1  Jungle Health and Safety Inspection Service    0.998895  \n",
       "2             Inadequate Protective Equipment.    0.999800  \n",
       "3                                       4.12.7    0.662557  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from natural_pdf import PDF\n",
    "import pandas as pd\n",
    "\n",
    "pdf = PDF(\"https://github.com/jsoma/natural-pdf/raw/refs/heads/main/pdfs/01-practice.pdf\")\n",
    "page = pdf.pages[0]\n",
    "\n",
    "# List of questions to ask\n",
    "questions = [\n",
    "    \"What is the inspection date?\",\n",
    "    \"What company was inspected?\",\n",
    "    \"What is statute 5.8.3 about?\",\n",
    "    \"How many violations were there in total?\" # This might be less reliable\n",
    "]\n",
    "\n",
    "# Collect answers for each question\n",
    "results = []\n",
    "for q in questions:\n",
    "    answer_dict = page.ask(q)\n",
    "    # Add the original question to the dictionary\n",
    "    answer_dict['question'] = q\n",
    "    results.append(answer_dict)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "# We select only the most relevant columns here\n",
    "df_results = pd.DataFrame(results)[['question', 'answer', 'confidence']]\n",
    "\n",
    "# Display the DataFrame\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccbb776",
   "metadata": {},
   "source": [
    "This shows how you can iterate through questions, collect the answer dictionaries, and then create a structured DataFrame, making it easy to review questions, answers, and their confidence levels together.\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "<p class=\"admonition-title\">QA Model and Limitations</p>\n",
    "\n",
    "    *   The QA system relies on underlying transformer models. Performance and confidence scores vary.\n",
    "    *   It works best for questions where the answer is explicitly stated. It cannot synthesize information or perform calculations (e.g., counting items might fail or return text containing a number rather than the count itself).\n",
    "    *   You can potentially specify different QA models via the `model=` argument in `page.ask()` if others are configured.\n",
    "</div> "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown"
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}