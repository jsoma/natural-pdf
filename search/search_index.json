{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Natural PDF","text":"<p>A friendly library for working with PDFs, built on top of pdfplumber.</p> <p>Natural PDF lets you find and extract content from PDFs using simple code that makes sense.</p> <ul> <li>Live demo here</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from natural_pdf import PDF\n\npdf = PDF('document.pdf')\npage = pdf.pages[0]\n\n# Find the title and get content below it\ntitle = page.find('text:contains(\"Summary\"):bold')\ncontent = title.below().extract_text()\n\n# Exclude everything above 'CONFIDENTIAL' and below last line on page\npage.add_exclusion(page.find('text:contains(\"CONFIDENTIAL\")').above())\npage.add_exclusion(page.find_all('line')[-1].below())\n\n# Get the clean text without header/footer\nclean_text = page.extract_text()\n</code></pre>"},{"location":"#what-can-you-do-with-natural-pdf","title":"What can you do with Natural PDF?","text":"<ul> <li>Find text using CSS-like selectors (like <code>page.find('text:contains(\"Revenue\"):bold')</code>)</li> <li>Navigate spatially (like <code>heading.below()</code> to get content below a heading)</li> <li>Extract text while automatically excluding headers and footers</li> <li>Visualize what's happening to debug your extraction</li> <li>Apply OCR to scanned documents</li> <li>Detect tables, headings, and other document structures using AI models</li> <li>Ask natural language questions to your documents</li> </ul>"},{"location":"#core-features","title":"Core Features","text":""},{"location":"#css-like-selectors","title":"CSS-like Selectors","text":"<pre><code># Find and extract text from bold elements containing \"Revenue\"\npage.find('text:contains(\"Revenue\"):bold').extract_text()\n\n# Extract all large text\npage.find_all('text[size&gt;=12]').extract_text()\n\n# Highlight red rectangles\npage.find_all('rect[color~=red]').highlight(color=\"red\")\n\n# Find text with specific font and extract it\npage.find_all('text[fontname*=Arial]').extract_text()\n\n# Highlight high-confidence OCR text\npage.find_all('text[source=ocr][confidence&gt;=0.8]').highlight(label=\"High Confidence OCR\")\n</code></pre> <p>Selectors support attribute matching, pseudo-classes, and content searches. Learn more about selectors \u2192</p> <p>Curious about those weird font names like 'AAAAAB+Arial'? Explore PDF font handling \u2192</p>"},{"location":"#spatial-navigation","title":"Spatial Navigation","text":"<pre><code># Extract text below a heading\nintro_text = page.find('text:contains(\"Introduction\")').below().extract_text()\n\n# Extract text from one heading to another\nmethods_text = page.find('text:contains(\"Methods\")').below(\n    until='text:contains(\"Results\")',\n    include_until=False\n).extract_text()\n\n# Extract content above a footer\nmain_text = page.find('text:contains(\"Page 1 of 10\")').above().extract_text()\n</code></pre> <p>Navigate PDFs spatially instead of using coordinates. Explore more navigation methods \u2192</p> <p>Working with headers and footers? Learn about exclusion zones \u2192</p>"},{"location":"#document-layout-analysis","title":"Document Layout Analysis","text":"<pre><code># Detect document structure using AI models\npage.analyze_layout()\n\n# Highlight titles and tables with different colors\npage.find_all('region[type=title]').highlight(color=\"purple\", label=\"Titles\")\npage.find_all('region[type=table]').highlight(color=\"blue\", label=\"Tables\")\n\n# Extract text from paragraphs\nparagraph_text = page.find_all('region[type=plain-text]').extract_text()\n\n# Extract data from the first table as a list of rows\ntable_data = page.find('region[type=table]').extract_table()\n</code></pre> <p>Natural PDF supports multiple layout models including YOLO for general document analysis and Table Transformer (TATR) for detailed table structure. Learn about layout models \u2192</p> <p>Working with tables? See specialized table extraction methods \u2192</p>"},{"location":"#document-question-answering","title":"Document Question Answering","text":"<pre><code># Ask questions directly to your documents\nresult = pdf.ask(\"What was the company's revenue in 2022?\")\nif result.get(\"found\", False):\n    print(f\"Answer: {result['answer']}\")\n    print(f\"Confidence: {result['confidence']:.2f}\")\n\n    # Highlight where the answer was found\n    if \"source_elements\" in result:\n        for element in result[\"source_elements\"]:\n            element.highlight(color=\"orange\")\n\n    # Display the answer location\n    image = pdf.pages[result.get('page_num', 0) - 1].to_image()\n    image\n</code></pre> <p>Document QA uses LayoutLM models that understand both text content and visual layout. Unlike general LLMs, the answers come directly from your document without hallucinations. Learn about Document QA \u2192</p> <p>Having OCR problems? Understand OCR challenges and solutions \u2192</p>"},{"location":"#ocr-support","title":"OCR Support","text":"<pre><code># Open a scanned document with OCR enabled\npdf = PDF('scanned_document.pdf', ocr=True)\n\n# Extract text with automatic OCR\ntext = pdf.pages[0].extract_text()\n\n# Apply OCR explicitly\nocr_elements = page.apply_ocr()\nprint(f\"Found {len(ocr_elements)} OCR text elements\")\n</code></pre> <p>Natural PDF supports both EasyOCR and PaddleOCR engines. PaddleOCR is often more accurate while EasyOCR is simpler to set up. Explore OCR options \u2192</p> <p>Got scanned documents or images? See how to optimize OCR results \u2192</p>"},{"location":"#visual-debugging","title":"Visual Debugging","text":"<pre><code># Highlight different elements\npage.find_all('text[size&gt;=14]').highlight(color=\"red\", label=\"Headings\")\npage.find_all('rect').highlight(color=\"green\", label=\"Boxes\")\npage.find_all('line').highlight(color=\"blue\", label=\"Lines\")\n\n# Highlight layout regions\npage.analyze_layout()\npage.find_all('region[type=table]').highlight(color=\"orange\", label=\"Tables\")\npage.find_all('region[type=title]').highlight(color=\"purple\", label=\"Titles\")\n\n# Get the visualization as an image (great for Jupyter notebooks)\nimage = page.to_image(labels=True)\nimage\n\n# Or save the image if needed\n# page.save_image(\"highlighted.png\", labels=True)\n</code></pre> <p>Visualizing elements helps debug extraction issues and understand document structure. Natural PDF provides color-coding and labels to make it clear what's being detected. See more visualization options \u2192</p> <p>Having trouble with PDF extraction? Understand common PDF challenges \u2192</p>"},{"location":"#page-sections","title":"Page Sections","text":"<p>Here's how to split pages into logical sections for extracting structured content:</p> <pre><code># Simple approach: Get content between headings\nintro_text = page.find('text:contains(\"Introduction\")').below(\n    until='text:contains(\"Methods\")', include_until=False\n).extract_text()\n\n# Get sections based on headings\nsections = page.get_sections(start_elements='text[size&gt;=14]:bold')\n\n# Process each section\nfor section in sections:\n    # Extract text from the section\n    section_text = section.extract_text()\n    print(f\"Section text: {section_text[:50]}...\")\n\n    # Highlight the section\n    section.highlight()\n\n# Get sections across multiple pages\ndoc_sections = pdf.pages.get_sections(\n    start_elements='text[size&gt;=14]:bold',\n    new_section_on_page_break=True\n)\n</code></pre> <p>Sections help break down documents into logical chunks. Use them to extract structured content like chapters, articles, or report sections. Learn more about sectioning \u2192</p> <p>Need to extract specific document components? See layout analysis for automatic structure detection \u2192</p>"},{"location":"#advanced-example","title":"Advanced Example","text":"<p>Here's a more complex example that uses multiple features:</p> <pre><code>from natural_pdf import PDF\nimport os\n\n# Create output directory\nos.makedirs(\"output\", exist_ok=True)\n\n# Open a PDF\npdf = PDF(\"annual_report.pdf\")\n\n# Add exclusion zones for header and footer\npdf.add_exclusion(\n    lambda page: page.find('text:contains(\"CONFIDENTIAL\")').above() if page.find('text:contains(\"CONFIDENTIAL\")') else None,\n    label=\"header\"\n)\npdf.add_exclusion(\n    lambda page: page.find('text:contains(\"Page\")').below() if page.find('text:contains(\"Page\")') else None,\n    label=\"footer\"\n)\n\n# Find financial section\nfinancial_heading = pdf.find('text:contains(\"Financial Results\")')\nif financial_heading:\n    page = financial_heading.page\n\n    # Run layout analysis\n    page.analyze_layout()\n\n    # Get the region below the heading\n    financial_section = financial_heading.below(height=300)\n    financial_section.highlight(color=\"yellow\", label=\"Financial Section\")\n\n    # Find tables in or near this section\n    tables = page.find_all('region[type=table]')\n    tables_in_section = [table for table in tables if financial_section.intersects(table)]\n\n    if tables_in_section:\n        # Highlight and extract tables\n        for i, table in enumerate(tables_in_section):\n            table.highlight(color=\"teal\", label=f\"Table {i+1}\")\n\n            # Extract table data\n            data = table.extract_table()\n            print(f\"\\nTable {i+1}:\")\n            for row in data:\n                print(row)\n\n    # Ask questions about the financial section\n    questions = [\n        \"What was the total revenue?\",\n        \"What was the net income?\",\n        \"What was the year-over-year growth?\"\n    ]\n\n    print(\"\\nDocument QA Results:\")\n    for question in questions:\n        result = financial_section.ask(question)\n        if result.get(\"found\", False):\n            print(f\"Q: {question}\")\n            print(f\"A: {result['answer']} (confidence: {result['confidence']:.2f})\")\n\n            # Highlight the answer\n            if \"source_elements\" in result:\n                for elem in result[\"source_elements\"]:\n                    elem.highlight(color=\"red\", label=f\"Answer: {question}\")\n\n    # Get the highlighted page as an image\n    image = page.to_image(labels=True)\n    # Just return the image as the last line in a Jupyter cell\n    image\n\n    # Extract text from the financial section\n    financial_text = financial_section.extract_text()\n    print(f\"\\nExtracted text from Financial Section ({len(financial_text)} characters):\")\n    print(financial_text[:200] + \"...\" if len(financial_text) &gt; 200 else financial_text)\n</code></pre>"},{"location":"#documentation-topics","title":"Documentation Topics","text":"<p>Choose what you want to learn about:</p>"},{"location":"#task-based-guides","title":"Task-based Guides","text":"<ul> <li>Getting Started: Install the library and run your first extraction</li> <li>PDF Navigation: Open PDFs and work with pages</li> <li>Element Selection: Find text and other elements using selectors</li> <li>Text Extraction: Extract clean text from documents</li> <li>Regions: Work with specific areas of a page</li> <li>Visual Debugging: See what you're extracting</li> <li>OCR: Extract text from scanned documents</li> <li>Layout Analysis: Detect document structure</li> <li>Tables: Extract tabular data</li> <li>Document QA: Ask questions to your documents</li> </ul>"},{"location":"#understanding-pdfs","title":"Understanding PDFs","text":"<ul> <li>PDF Explanations: Deep dives into PDF extraction challenges, fonts, OCR, and more</li> </ul>"},{"location":"#reference","title":"Reference","text":"<ul> <li>API Reference: Complete library reference</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>This section provides detailed documentation for all the classes and methods in Natural PDF.</p>"},{"location":"api/#core-classes","title":"Core Classes","text":""},{"location":"api/#pdf-class","title":"PDF Class","text":"<p>The main entry point for working with PDFs.</p> <pre><code>class PDF:\n    \"\"\"\n    The main entry point for working with PDFs.\n\n    Parameters:\n        path (str): Path to the PDF file.\n        password (str, optional): Password for encrypted PDFs. Default: None\n        reading_order (bool, optional): Sort elements in reading order. Default: True\n        keep_spaces (bool, optional): Keep spaces in word elements. Default: True\n        font_attrs (list, optional): Font attributes to use for text grouping. \n                                    Default: ['fontname', 'size']\n        ocr (bool/dict/str, optional): OCR configuration. Default: False\n        ocr_engine (str/Engine, optional): OCR engine to use. Default: \"easyocr\"\n    \"\"\"\n</code></pre> <p>Main Methods</p> Method Description Parameters Returns <code>pages</code> Access pages in the document N/A (property) <code>PageCollection</code> <code>extract_text(keep_blank_chars=True, apply_exclusions=True)</code> Extract text from all pages <code>keep_blank_chars</code>: Whether to keep blank characters<code>apply_exclusions</code>: Whether to apply exclusion zones <code>str</code>: Extracted text <code>find(selector, case=True, regex=False, apply_exclusions=True)</code> Find first element matching selector across all pages <code>selector</code>: CSS-like selector string<code>case</code>: Case-sensitive search<code>regex</code>: Use regex for :contains()<code>apply_exclusions</code>: Whether to apply exclusion zones <code>Element</code> or <code>None</code> <code>find_all(selector, case=True, regex=False, apply_exclusions=True)</code> Find all elements matching selector across all pages <code>selector</code>: CSS-like selector string<code>case</code>: Case-sensitive search<code>regex</code>: Use regex for :contains()<code>apply_exclusions</code>: Whether to apply exclusion zones <code>ElementCollection</code> <code>add_exclusion(func, label=None)</code> Add a document-wide exclusion zone <code>func</code>: Function taking a page and returning region<code>label</code>: Optional label for the exclusion <code>None</code> <code>get_sections(start_elements, end_elements=None, boundary_inclusion='start')</code> Get sections across all pages <code>start_elements</code>: Elements marking section starts<code>end_elements</code>: Elements marking section ends<code>boundary_inclusion</code>: How to include boundaries ('start', 'end', 'both', 'none') <code>list[Region]</code> <code>ask(question, min_confidence=0.0, model=None)</code> Ask a question about the document content <code>question</code>: Question to ask<code>min_confidence</code>: Minimum confidence threshold<code>model</code>: Optional model name or path <code>dict</code>: Result with answer and metadata"},{"location":"api/#page-class","title":"Page Class","text":"<p>Represents a single page in a PDF document.</p> <pre><code>class Page:\n    \"\"\"\n    Represents a single page in a PDF document.\n\n    Properties:\n        page_number (int): 1-indexed page number\n        page_index (int): 0-indexed page position\n        width (float): Page width in points\n        height (float): Page height in points\n        pdf (PDF): Parent PDF object\n    \"\"\"\n</code></pre> <p>Main Methods</p> Method Description Parameters Returns <code>extract_text(keep_blank_chars=True, apply_exclusions=True, ocr=None)</code> Extract text from the page <code>keep_blank_chars</code>: Whether to keep blank characters<code>apply_exclusions</code>: Whether to apply exclusion zones<code>ocr</code>: Whether to force OCR <code>str</code>: Extracted text <code>find(selector, case=True, regex=False, apply_exclusions=True)</code> Find the first element matching selector <code>selector</code>: CSS-like selector string<code>case</code>: Case-sensitive search<code>regex</code>: Use regex for :contains()<code>apply_exclusions</code>: Whether to apply exclusion zones <code>Element</code> or <code>None</code> <code>find_all(selector, case=True, regex=False, apply_exclusions=True)</code> Find all elements matching selector <code>selector</code>: CSS-like selector string<code>case</code>: Case-sensitive search<code>regex</code>: Use regex for :contains()<code>apply_exclusions</code>: Whether to apply exclusion zones <code>ElementCollection</code> <code>create_region(x0, top, x1, bottom)</code> Create a region at specific coordinates <code>x0</code>: Left coordinate<code>top</code>: Top coordinate<code>x1</code>: Right coordinate<code>bottom</code>: Bottom coordinate <code>Region</code> <code>highlight(elements, color=None, label=None)</code> Highlight elements on the page <code>elements</code>: Elements to highlight<code>color</code>: RGBA color tuple<code>label</code>: Label for the highlight <code>Page</code> (self) <code>highlight_all(include_types=None, include_text_styles=False, include_layout_regions=False)</code> Highlight all elements on the page <code>include_types</code>: Element types to include<code>include_text_styles</code>: Whether to include text styles<code>include_layout_regions</code>: Whether to include layout regions <code>Page</code> (self) <code>save_image(path, resolution=72, labels=True)</code> Save an image of the page with highlights <code>path</code>: Path to save image<code>resolution</code>: Image resolution in DPI<code>labels</code>: Whether to include labels <code>None</code> <code>to_image(resolution=72, labels=True)</code> Get a PIL Image of the page with highlights <code>resolution</code>: Image resolution in DPI<code>labels</code>: Whether to include labels <code>PIL.Image</code> <code>analyze_text_styles()</code> Group text by visual style properties None <code>dict</code>: Mapping of style name to elements <code>analyze_layout(model=\"yolo\", confidence=0.2, existing=\"replace\")</code> Detect layout regions using ML models <code>model</code>: Model to use (\"yolo\", \"tatr\")<code>confidence</code>: Confidence threshold<code>existing</code>: How to handle existing regions <code>ElementCollection</code>: Detected regions <code>add_exclusion(region, label=None)</code> Add an exclusion zone to the page <code>region</code>: Region to exclude<code>label</code>: Optional label for the exclusion <code>Region</code>: The exclusion region <code>get_sections(start_elements, end_elements=None, boundary_inclusion='start')</code> Get sections from the page <code>start_elements</code>: Elements marking section starts<code>end_elements</code>: Elements marking section ends<code>boundary_inclusion</code>: How to include boundaries <code>list[Region]</code> <code>ask(question, min_confidence=0.0, model=None, debug=False)</code> Ask a question about the page content <code>question</code>: Question to ask<code>min_confidence</code>: Minimum confidence threshold<code>model</code>: Optional model name or path<code>debug</code>: Whether to save debug files <code>dict</code>: Result with answer and metadata <code>apply_ocr(languages=None, min_confidence=0.0, **kwargs)</code> Apply OCR to the page <code>languages</code>: Languages to use<code>min_confidence</code>: Minimum confidence threshold<code>**kwargs</code>: Additional OCR engine parameters <code>ElementCollection</code>: OCR text elements"},{"location":"api/#region-class","title":"Region Class","text":"<p>Represents a rectangular area on a page.</p> <pre><code>class Region:\n    \"\"\"\n    Represents a rectangular area on a page.\n\n    Properties:\n        x0 (float): Left coordinate\n        top (float): Top coordinate\n        x1 (float): Right coordinate\n        bottom (float): Bottom coordinate\n        width (float): Width of the region\n        height (float): Height of the region\n        page (Page): Parent page object\n    \"\"\"\n</code></pre> <p>Main Methods</p> Method Description Parameters Returns <code>extract_text(keep_blank_chars=True, apply_exclusions=True, ocr=None)</code> Extract text from the region <code>keep_blank_chars</code>: Whether to keep blank characters<code>apply_exclusions</code>: Whether to apply exclusion zones<code>ocr</code>: Whether to force OCR <code>str</code>: Extracted text <code>find(selector, case=True, regex=False, apply_exclusions=True)</code> Find the first element matching selector within the region <code>selector</code>: CSS-like selector string<code>case</code>: Case-sensitive search<code>regex</code>: Use regex for :contains()<code>apply_exclusions</code>: Whether to apply exclusion zones <code>Element</code> or <code>None</code> <code>find_all(selector, case=True, regex=False, apply_exclusions=True)</code> Find all elements matching selector within the region <code>selector</code>: CSS-like selector string<code>case</code>: Case-sensitive search<code>regex</code>: Use regex for :contains()<code>apply_exclusions</code>: Whether to apply exclusion zones <code>ElementCollection</code> <code>expand(left=0, top=0, right=0, bottom=0, width_factor=1.0, height_factor=1.0)</code> Expand the region in specified directions <code>left/top/right/bottom</code>: Points to expand in each direction<code>width_factor/height_factor</code>: Scale width/height by this factor <code>Region</code>: Expanded region <code>highlight(color=None, label=None, include_attrs=None)</code> Highlight the region <code>color</code>: RGBA color tuple<code>label</code>: Label for the highlight<code>include_attrs</code>: Region attributes to display <code>Region</code> (self) <code>to_image(resolution=72, crop_only=False)</code> Get a PIL Image of just the region <code>resolution</code>: Image resolution in DPI<code>crop_only</code>: Whether to exclude border <code>PIL.Image</code> <code>save_image(path, resolution=72, crop_only=False)</code> Save an image of just the region <code>path</code>: Path to save image<code>resolution</code>: Image resolution in DPI<code>crop_only</code>: Whether to exclude border <code>None</code> <code>get_sections(start_elements, end_elements=None, boundary_inclusion='start')</code> Get sections within the region <code>start_elements</code>: Elements marking section starts<code>end_elements</code>: Elements marking section ends<code>boundary_inclusion</code>: How to include boundaries <code>list[Region]</code> <code>ask(question, min_confidence=0.0, model=None, debug=False)</code> Ask a question about the region content <code>question</code>: Question to ask<code>min_confidence</code>: Minimum confidence threshold<code>model</code>: Optional model name or path<code>debug</code>: Whether to save debug files <code>dict</code>: Result with answer and metadata <code>extract_table(method=None, table_settings=None, use_ocr=False)</code> Extract table data from the region <code>method</code>: Extraction method (\"plumber\", \"tatr\")<code>table_settings</code>: Custom settings for extraction<code>use_ocr</code>: Whether to use OCR text <code>list</code>: Table data as rows and columns <code>intersects(other)</code> Check if this region intersects with another <code>other</code>: Another region <code>bool</code>: True if regions intersect <code>contains(x, y)</code> Check if a point is within the region <code>x</code>: X coordinate<code>y</code>: Y coordinate <code>bool</code>: True if point is in region"},{"location":"api/#element-types","title":"Element Types","text":""},{"location":"api/#element-base-class","title":"Element Base Class","text":"<p>The base class for all PDF elements.</p> <pre><code>class Element:\n    \"\"\"\n    Base class for all PDF elements.\n\n    Properties:\n        x0 (float): Left coordinate\n        top (float): Top coordinate\n        x1 (float): Right coordinate\n        bottom (float): Bottom coordinate\n        width (float): Width of the element\n        height (float): Height of the element\n        page (Page): Parent page object\n    \"\"\"\n</code></pre> <p>Main Methods</p> Method Description Parameters Returns <code>above(height=None, full_width=True, until=None, include_until=True)</code> Create a region above the element <code>height</code>: Height of region<code>full_width</code>: Whether to span page width<code>until</code>: Selector for boundary<code>include_until</code>: Whether to include boundary <code>Region</code> <code>below(height=None, full_width=True, until=None, include_until=True)</code> Create a region below the element <code>height</code>: Height of region<code>full_width</code>: Whether to span page width<code>until</code>: Selector for boundary<code>include_until</code>: Whether to include boundary <code>Region</code> <code>select_until(selector, include_endpoint=True, full_width=True)</code> Create a region from this element to another <code>selector</code>: Selector for endpoint<code>include_endpoint</code>: Whether to include endpoint<code>full_width</code>: Whether to span page width <code>Region</code> <code>highlight(color=None, label=None, include_attrs=None)</code> Highlight this element <code>color</code>: RGBA color tuple<code>label</code>: Label for the highlight<code>include_attrs</code>: Element attributes to display <code>Element</code> (self) <code>extract_text(keep_blank_chars=True, apply_exclusions=True)</code> Extract text from this element <code>keep_blank_chars</code>: Whether to keep blank characters<code>apply_exclusions</code>: Whether to apply exclusion zones <code>str</code>: Extracted text <code>next(selector=None, limit=None, apply_exclusions=True)</code> Get the next element in reading order <code>selector</code>: Optional selector to filter<code>limit</code>: How many elements to search<code>apply_exclusions</code>: Whether to apply exclusion zones <code>Element</code> or <code>None</code> <code>prev(selector=None, limit=None, apply_exclusions=True)</code> Get the previous element in reading order <code>selector</code>: Optional selector to filter<code>limit</code>: How many elements to search<code>apply_exclusions</code>: Whether to apply exclusion zones <code>Element</code> or <code>None</code> <code>nearest(selector, max_distance=None, apply_exclusions=True)</code> Get the nearest element matching selector <code>selector</code>: Selector for elements<code>max_distance</code>: Maximum distance in points<code>apply_exclusions</code>: Whether to apply exclusion zones <code>Element</code> or <code>None</code>"},{"location":"api/#textelement","title":"TextElement","text":"<p>Represents text elements in the PDF.</p> <pre><code>class TextElement(Element):\n    \"\"\"\n    Represents text elements in the PDF.\n\n    Additional Properties:\n        text (str): The text content\n        fontname (str): The font name\n        size (float): The font size\n        bold (bool): Whether the text is bold\n        italic (bool): Whether the text is italic\n        color (tuple): The text color as RGB tuple\n        confidence (float): OCR confidence (for OCR text)\n        source (str): 'pdf' or 'ocr'\n    \"\"\"\n</code></pre> <p>Main Properties</p> Property Type Description <code>text</code> <code>str</code> The text content <code>fontname</code> <code>str</code> The font name <code>size</code> <code>float</code> The font size <code>bold</code> <code>bool</code> Whether the text is bold <code>italic</code> <code>bool</code> Whether the text is italic <code>color</code> <code>tuple</code> The text color as RGB tuple <code>confidence</code> <code>float</code> OCR confidence (for OCR text) <code>source</code> <code>str</code> 'pdf' or 'ocr' <code>font_variant</code> <code>str</code> Font variant identifier (e.g., 'AAAAAB+') <p>Additional Methods</p> Method Description Parameters Returns <code>font_info()</code> Get detailed font information None <code>dict</code>: Font properties"},{"location":"api/#collections","title":"Collections","text":""},{"location":"api/#elementcollection","title":"ElementCollection","text":"<p>A collection of elements with batch operations.</p> <pre><code>class ElementCollection:\n    \"\"\"\n    A collection of elements with batch operations.\n\n    This class provides operations that can be applied to multiple elements at once.\n    \"\"\"\n</code></pre> <p>Main Methods</p> Method Description Parameters Returns <code>extract_text(keep_blank_chars=True, apply_exclusions=True)</code> Extract text from all elements <code>keep_blank_chars</code>: Whether to keep blank characters<code>apply_exclusions</code>: Whether to apply exclusion zones <code>str</code>: Extracted text <code>filter(selector)</code> Filter elements by selector <code>selector</code>: CSS-like selector string <code>ElementCollection</code> <code>highlight(color=None, label=None, include_attrs=None)</code> Highlight all elements <code>color</code>: RGBA color tuple<code>label</code>: Label for the highlight<code>include_attrs</code>: Attributes to display <code>ElementCollection</code> (self) <code>first</code> Get the first element in the collection N/A (property) <code>Element</code> or <code>None</code> <code>last</code> Get the last element in the collection N/A (property) <code>Element</code> or <code>None</code> <code>highest()</code> Get the highest element on the page None <code>Element</code> or <code>None</code> <code>lowest()</code> Get the lowest element on the page None <code>Element</code> or <code>None</code> <code>leftmost()</code> Get the leftmost element on the page None <code>Element</code> or <code>None</code> <code>rightmost()</code> Get the rightmost element on the page None <code>Element</code> or <code>None</code> <code>__len__()</code> Get the number of elements None <code>int</code> <code>__getitem__(index)</code> Get an element by index <code>index</code>: Index or slice <code>Element</code> or <code>ElementCollection</code>"},{"location":"api/#pagecollection","title":"PageCollection","text":"<p>A collection of pages with cross-page operations.</p> <pre><code>class PageCollection:\n    \"\"\"\n    A collection of pages with cross-page operations.\n\n    This class provides operations that can be applied across multiple pages.\n    \"\"\"\n</code></pre> <p>Main Methods</p> Method Description Parameters Returns <code>extract_text(keep_blank_chars=True, apply_exclusions=True)</code> Extract text from all pages <code>keep_blank_chars</code>: Whether to keep blank characters<code>apply_exclusions</code>: Whether to apply exclusion zones <code>str</code>: Extracted text <code>find(selector, case=True, regex=False, apply_exclusions=True)</code> Find the first element matching selector across all pages <code>selector</code>: CSS-like selector string<code>case</code>: Case-sensitive search<code>regex</code>: Use regex for :contains()<code>apply_exclusions</code>: Whether to apply exclusion zones <code>Element</code> or <code>None</code> <code>find_all(selector, case=True, regex=False, apply_exclusions=True)</code> Find all elements matching selector across all pages <code>selector</code>: CSS-like selector string<code>case</code>: Case-sensitive search<code>regex</code>: Use regex for :contains()<code>apply_exclusions</code>: Whether to apply exclusion zones <code>ElementCollection</code> <code>get_sections(start_elements, end_elements=None, boundary_inclusion='start', new_section_on_page_break=False)</code> Get sections spanning multiple pages <code>start_elements</code>: Elements marking section starts<code>end_elements</code>: Elements marking section ends<code>boundary_inclusion</code>: How to include boundaries<code>new_section_on_page_break</code>: Whether to start new sections at page breaks <code>list[Region]</code> <code>__len__()</code> Get the number of pages None <code>int</code> <code>__getitem__(index)</code> Get a page by index <code>index</code>: Index or slice <code>Page</code> or <code>PageCollection</code>"},{"location":"api/#ocr-classes","title":"OCR Classes","text":""},{"location":"api/#ocrengine","title":"OCREngine","text":"<p>Base class for OCR engines.</p> <pre><code>class OCREngine:\n    \"\"\"\n    Base class for OCR engines.\n\n    This class provides the interface for OCR engines.\n    \"\"\"\n</code></pre> <p>Main Methods</p> Method Description Parameters Returns <code>process_image(image, languages=None, min_confidence=0.0, **kwargs)</code> Process an image with OCR <code>image</code>: PIL Image<code>languages</code>: Languages to use<code>min_confidence</code>: Minimum confidence threshold <code>list</code>: OCR results"},{"location":"api/#easyocrengine","title":"EasyOCREngine","text":"<p>OCR engine using EasyOCR.</p> <pre><code>class EasyOCREngine(OCREngine):\n    \"\"\"\n    OCR engine using EasyOCR.\n\n    Parameters:\n        model_dir (str, optional): Directory for models. Default: None\n    \"\"\"\n</code></pre>"},{"location":"api/#paddleocrengine","title":"PaddleOCREngine","text":"<p>OCR engine using PaddleOCR.</p> <pre><code>class PaddleOCREngine(OCREngine):\n    \"\"\"\n    OCR engine using PaddleOCR.\n\n    Parameters:\n        use_angle_cls (bool, optional): Use text direction classification. Default: False\n        lang (str, optional): Language code. Default: \"en\"\n        det (bool, optional): Use text detection. Default: True\n        rec (bool, optional): Use text recognition. Default: True\n        cls (bool, optional): Use text direction classification. Default: False\n        det_model_dir (str, optional): Detection model directory. Default: None\n        rec_model_dir (str, optional): Recognition model directory. Default: None\n        verbose (bool, optional): Enable verbose output. Default: False\n    \"\"\"\n</code></pre>"},{"location":"api/#document-qa-classes","title":"Document QA Classes","text":""},{"location":"api/#documentqa","title":"DocumentQA","text":"<p>Class for document question answering.</p> <pre><code>class DocumentQA:\n    \"\"\"\n    Class for document question answering.\n\n    Parameters:\n        model (str, optional): Model name or path. Default: \"microsoft/layoutlmv3-base\"\n        device (str, optional): Device to use. Default: \"cpu\"\n        verbose (bool, optional): Enable verbose output. Default: False\n    \"\"\"\n</code></pre> <p>Main Methods</p> Method Description Parameters Returns <code>ask(question, image, word_boxes, min_confidence=0.0, max_answer_length=None, language=None)</code> Ask a question about a document <code>question</code>: Question to ask<code>image</code>: Document image<code>word_boxes</code>: Text positions<code>min_confidence</code>: Minimum confidence threshold<code>max_answer_length</code>: Maximum answer length<code>language</code>: Language code <code>dict</code>: Result with answer and metadata"},{"location":"api/#selector-syntax","title":"Selector Syntax","text":"<p>Natural PDF uses a CSS-like selector syntax to find elements in PDFs.</p>"},{"location":"api/#basic-selectors","title":"Basic Selectors","text":"Selector Description Example <code>element_type</code> Match elements of this type <code>text</code>, <code>rect</code>, <code>line</code> <code>[attribute=value]</code> Match elements with this attribute value <code>[fontname=Arial]</code>, <code>[size=12]</code> <code>[attribute&gt;=value]</code> Match elements with attribute &gt;= value <code>[size&gt;=12]</code> <code>[attribute&lt;=value]</code> Match elements with attribute &lt;= value <code>[size&lt;=10]</code> <code>[attribute~=value]</code> Match elements with attribute approximately equal <code>[color~=red]</code>, <code>[color~=(1,0,0)]</code> <code>[attribute*=value]</code> Match elements with attribute containing value <code>[fontname*=Arial]</code>"},{"location":"api/#pseudo-classes","title":"Pseudo-Classes","text":"Pseudo-Class Description Example <code>:contains(\"text\")</code> Match elements containing text <code>text:contains(\"Summary\")</code> <code>:starts-with(\"text\")</code> Match elements starting with text <code>text:starts-with(\"Summary\")</code> <code>:ends-with(\"text\")</code> Match elements ending with text <code>text:ends-with(\"2023\")</code> <code>:bold</code> Match bold text <code>text:bold</code> <code>:italic</code> Match italic text <code>text:italic</code>"},{"location":"api/#attribute-names","title":"Attribute Names","text":"Attribute Element Types Description <code>fontname</code> text Font name <code>size</code> text Font size <code>color</code> text, rect, line Color <code>width</code> rect, line Width <code>height</code> rect Height <code>confidence</code> text (OCR) OCR confidence score <code>source</code> text Source ('pdf' or 'ocr') <code>type</code> region Region type (e.g., 'table', 'title') <code>model</code> region Layout model that detected the region <code>font-variant</code> text Font variant identifier"},{"location":"api/#constants-and-configuration","title":"Constants and Configuration","text":""},{"location":"api/#color-names","title":"Color Names","text":"<p>Natural PDF supports color names in selectors.</p> Color Name RGB Value Example <code>red</code> (1, 0, 0) <code>[color~=red]</code> <code>green</code> (0, 1, 0) <code>[color~=green]</code> <code>blue</code> (0, 0, 1) <code>[color~=blue]</code> <code>black</code> (0, 0, 0) <code>[color~=black]</code> <code>white</code> (1, 1, 1) <code>[color~=white]</code>"},{"location":"api/#region-types","title":"Region Types","text":"<p>Layout analysis models detect the following region types:</p> Model Region Types YOLO <code>title</code>, <code>plain-text</code>, <code>table</code>, <code>figure</code>, <code>figure_caption</code>, <code>table_caption</code>, <code>table_footnote</code>, <code>isolate_formula</code>, <code>formula_caption</code>, <code>abandon</code> TATR <code>table</code>, <code>table-row</code>, <code>table-column</code>, <code>table-column-header</code>"},{"location":"document-qa/","title":"Document Question Answering","text":"<p>Natural PDF includes document QA functionality that allows you to ask natural language questions about your PDFs and get relevant answers. This feature uses LayoutLM models to understand both the text content and the visual layout of your documents.</p>"},{"location":"document-qa/#basic-usage","title":"Basic Usage","text":"<p>Here's how to ask questions to a PDF document:</p> <pre><code>from natural_pdf import PDF\n\n# Open a PDF\npdf = PDF('document.pdf')\n\n# Ask a question about the entire document\nresult = pdf.ask(\"What is the total revenue reported?\")\n\n# Get the answer\nif result.get(\"found\", False):\n    print(f\"Answer: {result['answer']}\")\n    print(f\"Confidence: {result['confidence']:.2f}\")\n    print(f\"Found on page: {result.get('page_num', 0)}\")\nelse:\n    print(\"No answer found.\")\n</code></pre>"},{"location":"document-qa/#asking-questions-to-specific-pages","title":"Asking Questions to Specific Pages","text":"<p>You can also ask questions to a specific page:</p> <pre><code># Get a page\npage = pdf.pages[0]\n\n# Ask a question just about this page\nresult = page.ask(\"Who is the CEO?\")\n\n# Get the answer\nif result.get(\"found\", False):\n    print(f\"Answer: {result['answer']}\")\n    print(f\"Confidence: {result['confidence']:.2f}\")\n\n    # Access the source elements that contain the answer\n    if \"source_elements\" in result:\n        # Highlight the answer\n        for element in result[\"source_elements\"]:\n            element.highlight(color=(1, 0.5, 0, 0.3))\n\n        # Save the highlighted image\n        page.save_image(\"answer_highlighted.png\")\n</code></pre>"},{"location":"document-qa/#asking-questions-to-regions","title":"Asking Questions to Regions","text":"<p>You can even ask questions to specific regions of a page:</p> <pre><code># Find a region\ntitle = page.find('text:contains(\"Financial Report\")')\nfinancial_section = title.below(height=300)\n\n# Ask a question just about this region\nresult = financial_section.ask(\"What was the net profit?\")\n\n# Get the answer\nif result.get(\"found\", False):\n    print(f\"Answer: {result['answer']}\")\n    print(f\"Confidence: {result['confidence']:.2f}\")\n\n    # Highlight the region and the answer\n    financial_section.highlight(color=(0, 0, 1, 0.2), label=\"Financial Section\")\n\n    if \"source_elements\" in result:\n        for element in result[\"source_elements\"]:\n            element.highlight(color=(1, 0, 0, 0.3), label=\"Answer\")\n\n    # Save the highlighted image\n    page.save_image(\"region_answer.png\")\n</code></pre>"},{"location":"document-qa/#controlling-model-and-parameters","title":"Controlling Model and Parameters","text":"<p>You can control which model is used and set various parameters:</p> <pre><code># Specify a different model\nresult = pdf.ask(\n    \"What was the company's revenue in 2022?\",\n    model=\"microsoft/layoutlmv3-large\"\n)\n\n# Set a higher confidence threshold for more reliable answers\nresult = pdf.ask(\n    \"What year was the company founded?\", \n    min_confidence=0.8  # Only accept answers with 80%+ confidence\n)\n\n# Control image resolution for better accuracy\nresult = page.ask(\n    \"What is the CEO's name?\",\n    resolution=300  # Higher resolution for better text recognition\n)\n\n# Set a maximum length for the answer\nresult = page.ask(\n    \"Summarize the business outlook\",\n    max_answer_length=50  # Keep the answer concise\n)\n\n# Specify the language for non-English documents\nresult = pdf.ask(\n    \"Quels sont les revenus totaux?\",\n    language=\"fr\"  # Use French for the question and answer\n)\n</code></pre>"},{"location":"document-qa/#handling-ocr-documents","title":"Handling OCR Documents","text":"<p>Document QA works with both native text PDF documents and scanned documents requiring OCR:</p> <pre><code># For a scanned document, enable OCR\npdf = PDF('scanned_document.pdf', ocr=True)\n\n# Ask a question - OCR will be automatically applied if needed\nresult = pdf.ask(\"What is the date of the report?\")\n\n# You can explicitly control OCR behavior\nresult = page.ask(\n    \"Who signed the document?\",\n    use_ocr=True,  # Force OCR even if there's native text\n    ocr_languages=[\"en\"]  # Specify OCR language\n)\n</code></pre> <p>For best results with scanned documents, you might need to fine-tune OCR settings. See our OCR Challenges and Solutions guide for detailed advice on improving OCR quality before applying Document QA.</p>"},{"location":"document-qa/#debugging-and-troubleshooting","title":"Debugging and Troubleshooting","text":"<p>If you're having trouble with document QA, you can enable debugging to see more details:</p> <pre><code># Enable debug mode to save intermediate files\nresult = page.ask(\n    \"What is the company's mission statement?\",\n    debug=True  # Will save images and word boxes to the output directory\n)\n</code></pre> <p>This will save: - The input image - The extracted word boxes - A visualization of the word boxes - The raw result from the model</p> <p>You can also specify a custom debug directory:</p> <pre><code>result = page.ask(\n    \"What is the company's mission statement?\",\n    debug=True,\n    debug_dir=\"qa_debug\"  # Save debug files to this directory\n)\n</code></pre>"},{"location":"document-qa/#handling-complex-documents","title":"Handling Complex Documents","text":"<p>For complex documents, you might want to break them down into focused questions:</p> <pre><code># First find the relevant section\nfinancial_section = pdf.find('text:contains(\"Financial Results\")').below(height=500)\n\n# Then ask specific questions about that section\nprofit_result = financial_section.ask(\"What was the net profit?\")\nrevenue_result = financial_section.ask(\"What was the total revenue?\")\ngrowth_result = financial_section.ask(\"What was the year-over-year growth?\")\n\n# Combine the answers\nif profit_result.get(\"found\") and revenue_result.get(\"found\"):\n    print(f\"Net profit: {profit_result['answer']}\")\n    print(f\"Total revenue: {revenue_result['answer']}\")\n    if growth_result.get(\"found\"):\n        print(f\"Growth: {growth_result['answer']}\")\n\n    # Highlight all answers with different colors\n    if \"source_elements\" in profit_result:\n        for elem in profit_result[\"source_elements\"]:\n            elem.highlight(color=(1, 0, 0, 0.3), label=\"Profit\")\n\n    if \"source_elements\" in revenue_result:\n        for elem in revenue_result[\"source_elements\"]:\n            elem.highlight(color=(0, 1, 0, 0.3), label=\"Revenue\")\n\n    if \"source_elements\" in growth_result:\n        for elem in growth_result[\"source_elements\"]:\n            elem.highlight(color=(0, 0, 1, 0.3), label=\"Growth\")\n\n    # Save the visualization\n    financial_section.page.save_image(\"financial_answers.png\", labels=True)\n</code></pre>"},{"location":"document-qa/#preprocessing-documents-for-better-results","title":"Preprocessing Documents for Better Results","text":"<p>For best results, you might want to prepare your documents:</p> <pre><code># Remove headers and footers\npdf.add_exclusion(\n    lambda page: page.find('text:contains(\"Confidential\")').above(),\n    label=\"header\"\n)\npdf.add_exclusion(\n    lambda page: page.find('text:contains(\"Page\")').below(),\n    label=\"footer\"\n)\n\n# Find the main content area and focus questions there\nfor page in pdf.pages:\n    # Apply layout analysis to find the main content\n    page.analyze_layout()\n\n    # Get text regions\n    text_regions = page.find_all('region[type=plain-text]')\n\n    # Ask questions about the main content\n    for region in text_regions:\n        result = region.ask(\"What is the main topic discussed?\")\n        if result.get(\"found\", False) and result.get(\"confidence\", 0) &gt; 0.7:\n            print(f\"Page {page.page_number}, Topic: {result['answer']}\")\n</code></pre>"},{"location":"document-qa/#a-complete-document-qa-example","title":"A Complete Document QA Example","text":"<p>Here's a complete example that walks through the document QA process:</p> <pre><code>from natural_pdf import PDF\nimport os\n\n# Create output directory if it doesn't exist\nos.makedirs(\"qa_results\", exist_ok=True)\n\n# Open a PDF\npdf = PDF('annual_report.pdf')\n\n# First, ask a general question to find the most relevant page\nresult = pdf.ask(\"Where is the financial summary?\")\nif result.get(\"found\", False):\n    print(f\"Financial summary is on page {result.get('page_num', 0)}\")\n    page = pdf.pages[result.get('page_num', 0) - 1]  # Convert to 0-indexed\nelse:\n    # Default to first page if not found\n    page = pdf.pages[0]\n    print(\"Financial summary location not found, using first page\")\n\n# Apply layout analysis to find regions\npage.analyze_layout()\n\n# Find the table regions\ntables = page.find_all('region[type=table]')\nprint(f\"Found {len(tables)} tables on page {page.page_number}\")\n\n# Ask questions about each table\nfor i, table in enumerate(tables):\n    # Extract table data\n    table_data = table.extract_table()\n\n    # Highlight the table\n    table.highlight(color=(0, 0, 1, 0.2), label=f\"Table {i+1}\")\n\n    # Ask questions about the table\n    revenue_result = table.ask(\"What was the total revenue?\")\n    profit_result = table.ask(\"What was the net profit?\")\n\n    print(f\"\\nTable {i+1}:\")\n    if revenue_result.get(\"found\", False):\n        print(f\"  Revenue: {revenue_result['answer']} (confidence: {revenue_result['confidence']:.2f})\")\n        # Highlight the answer\n        if \"source_elements\" in revenue_result:\n            for elem in revenue_result[\"source_elements\"]:\n                elem.highlight(color=(0, 1, 0, 0.3), label=\"Revenue\")\n\n    if profit_result.get(\"found\", False):\n        print(f\"  Net Profit: {profit_result['answer']} (confidence: {profit_result['confidence']:.2f})\")\n        # Highlight the answer\n        if \"source_elements\" in profit_result:\n            for elem in profit_result[\"source_elements\"]:\n                elem.highlight(color=(1, 0, 0, 0.3), label=\"Profit\")\n\n# Save the highlighted page\npage.save_image(\"qa_results/financial_qa.png\", labels=True)\n\n# Now ask about textual content\ntext_regions = page.find_all('region[type=plain-text]')\nfor i, region in enumerate(text_regions):\n    # Ask about this text region\n    summary_result = region.ask(\"What does this section discuss?\")\n\n    if summary_result.get(\"found\", False) and summary_result.get(\"confidence\", 0) &gt; 0.6:\n        print(f\"\\nText region {i+1}:\")\n        print(f\"  Topic: {summary_result['answer']}\")\n\n        # Highlight the region\n        region.highlight(color=(0.5, 0.5, 0, 0.2), label=f\"Text {i+1}: {summary_result['answer'][:20]}\")\n\n# Save the final highlighted page with all answers\npage.save_image(\"qa_results/page_qa_analysis.png\", labels=True)\n\n# Ask broader questions about the document\nbroad_questions = [\n    \"What was the company's overall performance?\",\n    \"What are the main business risks mentioned?\",\n    \"What is the outlook for next year?\"\n]\n\nprint(\"\\nDocument-wide insights:\")\nfor question in broad_questions:\n    result = pdf.ask(question)\n    if result.get(\"found\", False):\n        print(f\"\\nQ: {question}\")\n        print(f\"A: {result['answer']}\")\n        print(f\"   (confidence: {result['confidence']:.2f}, page: {result.get('page_num', 0)})\")\n</code></pre>"},{"location":"document-qa/#how-it-works","title":"How It Works","text":"<p>Document QA in Natural PDF:</p> <ol> <li>Extracts text elements and their positions from the PDF</li> <li>Renders a high-resolution image of the page or region</li> <li>Passes the image, text positions, and your question to a LayoutLM model</li> <li>Returns the answer with confidence score and source elements</li> </ol> <p>The use of layout-aware models (like LayoutLM) allows the system to understand both the textual content and the spatial layout of the document, making it more effective than text-only QA systems for documents with complex layouts.</p>"},{"location":"document-qa/#word-box-processing","title":"Word Box Processing","text":"<p>For technical users, here's how the system processes word boxes:</p> <pre><code># The document QA system converts text elements to word boxes like this:\nword_boxes = [\n    {\n        \"text\": \"Revenue\",\n        \"box\": [100, 200, 150, 220],  # [x0, y0, x1, y1] in pixel coordinates\n        \"page_num\": 1,\n        \"confidence\": 1.0  # For native text (non-OCR)\n    },\n    # More word boxes...\n]\n\n# These are then processed by the LayoutLM model along with the page image\n</code></pre>"},{"location":"document-qa/#technical-considerations","title":"Technical Considerations","text":"<p>When using document QA, consider these technical details:</p> <ul> <li>Memory Usage: Processing large documents or high-resolution images requires significant memory</li> <li>Speed: The first question may be slower as models are loaded; subsequent questions are faster</li> <li>Model Selection: Larger models (like layoutlmv3-large) are more accurate but slower</li> <li>OCR Quality: The quality of OCR text extraction directly impacts QA accuracy</li> <li>Image Resolution: Higher resolution improves accuracy but consumes more memory</li> <li>Answer Confidence: Always check the confidence score; lower scores may indicate uncertain answers</li> </ul>"},{"location":"document-qa/#next-steps","title":"Next Steps","text":"<p>Now that you know how to use document QA, you might want to explore:</p> <ul> <li>OCR for working with scanned documents first</li> <li>OCR Challenges and Solutions for improving OCR quality</li> <li>Layout Analysis for identifying regions to ask questions about</li> <li>Visual Debugging to visualize results</li> <li>Why Document QA is Better than LLMs for advantages over general LLMs</li> </ul>"},{"location":"element-selection/","title":"Finding Elements in PDFs","text":"<p>Natural PDF uses CSS-like selectors to find elements in PDFs. This helps you pinpoint exactly what you're looking for in a document.</p>"},{"location":"element-selection/#selector-structure","title":"Selector Structure","text":"<p>A Natural PDF selector is made up of these parts:</p> <pre><code>text[size&gt;=12][color~=red]:bold:contains('Summary')\n</code></pre> <ul> <li><code>text</code> - Element type (text, rect, line, etc.)</li> <li><code>[size&gt;=12][color~=red]</code> - Attributes with operators</li> <li><code>:bold:contains('Summary')</code> - Pseudo-classes</li> </ul>"},{"location":"element-selection/#types-of-elements-on-a-page","title":"Types of Elements on a Page","text":"<pre><code>graph TD\n    subgraph \"PDF Elements\"\n        text[Text Elements]\n        rect[Rectangles]\n        line[Lines]\n        image[Images]\n        region[Detected Regions]\n    end\n\n    style text fill:#bbf,stroke:#333\n    style rect fill:#fbf,stroke:#333\n    style line fill:#bfb,stroke:#333\n    style image fill:#fbb,stroke:#333\n    style region fill:#eff,stroke:#333</code></pre>"},{"location":"element-selection/#the-basics-finding-text","title":"The Basics: Finding Text","text":"<p>Let's start with the most common task: finding text in a PDF.</p> <pre><code>from natural_pdf import PDF\n\npdf = PDF('document.pdf')\npage = pdf.pages[0]\n\n# Find the first occurrence of \"Revenue\"\nrevenue = page.find('text:contains(\"Revenue\")')\nif revenue:\n    print(f\"Found Revenue at position {revenue.bbox}\")\n\n# Find all occurrences\nall_revenue = page.find_all('text:contains(\"Revenue\")')\nprint(f\"Found {len(all_revenue)} occurrences of Revenue\")\n</code></pre>"},{"location":"element-selection/#css-like-selectors","title":"CSS-like Selectors","text":"<p>Natural PDF uses selectors that will feel familiar if you know CSS:</p> <pre><code># Find bold text\nbold_text = page.find('text:bold')\n\n# Find large text (12pt or bigger)\nheadings = page.find_all('text[size&gt;=12]')\n\n# Find bold text that's at least 14pt and contains \"Summary\"\nsummary = page.find('text[size&gt;=14]:bold:contains(\"Summary\")')\n\n# Find colored text using color names\nred_text = page.find_all('text[color~=red]')\nblue_text = page.find_all('text[color~=blue]')\n# Also supports RGB values if needed\ndark_red_text = page.find_all('text[color~=(0.8,0,0)]')\n\n# Find thick lines\nthick_lines = page.find_all('line[width&gt;=2]')\n</code></pre>"},{"location":"element-selection/#selector-operators","title":"Selector Operators","text":"<p>Natural PDF supports various operators for attribute matching:</p> <p>Here's what each operator does:</p> Operator Description Example Use Case <code>=</code> Exact match <code>[fontname='Arial']</code> When you need exact matching <code>&gt;=</code> Greater than or equal <code>[size&gt;=12]</code> Finding larger text (headings) <code>&lt;=</code> Less than or equal <code>[size&lt;=8]</code> Finding smaller text (footnotes) <code>&gt;</code> Greater than <code>[width&gt;0.5]</code> Finding elements above a threshold <code>&lt;</code> Less than <code>[height&lt;2]</code> Finding elements below a threshold <code>~=</code> Approximate match <code>[color~=red]</code> Color matching (supports names, RGB, hex) <code>*=</code> Contains substring <code>[fontname*=Times]</code> Partial string matching"},{"location":"element-selection/#element-types","title":"Element Types","text":"<p>You can select different types of elements:</p> <pre><code># Find text elements\ntext = page.find_all('text')\n\n# Find rectangle elements (often used for backgrounds or borders)\nrects = page.find_all('rect')\n\n# Find line elements\nlines = page.find_all('line')\n\n# Find curve elements\ncurves = page.find_all('curve')\n\n# Find image elements\nimages = page.find_all('image')\n</code></pre>"},{"location":"element-selection/#advanced-text-searching","title":"Advanced Text Searching","text":"<p>For more flexible text searches:</p> <pre><code># Case-insensitive search\nresults = page.find_all('text:contains(\"annual report\")', case=False)\n\n# Regular expression search\n# Find all dates in format YYYY-MM-DD\ndates = page.find_all('text:contains(\"\\\\d{4}-\\\\d{2}-\\\\d{2}\")', regex=True)\n\n# Combine options\npage.find_all('text:contains(\"summary\")', regex=True, case=False)\n</code></pre>"},{"location":"element-selection/#selecting-multiple-elements-with-elementcollection","title":"Selecting Multiple Elements with ElementCollection","text":"<p>When you use <code>find_all()</code>, you get an <code>ElementCollection</code> that lets you work with multiple elements at once:</p> <pre><code># Find all headings\nheadings = page.find_all('text[size&gt;=14]:bold')\n\n# Get the first or last element\nfirst_heading = headings.first\nlast_heading = headings.last\n\n# Filter the collection further\nimportant_headings = headings.filter('text:contains(\"Financial\")')\n\n# Extract text from all elements in the collection\nall_heading_text = headings.extract_text()\n\n# Highlight all elements\nheadings.highlight(color=\"red\", label=\"Headings\")\n</code></pre>"},{"location":"element-selection/#font-properties-and-variants","title":"Font Properties and Variants","text":"<p>You can select text based on font properties:</p> <pre><code># Find text with a specific font\narial_text = page.find_all('text[fontname*=Arial]')\n\n# Find bold or italic text\nbold_text = page.find_all('text:bold')\nitalic_text = page.find_all('text:italic')\n\n# Find text with specific size\nbig_text = page.find_all('text[size&gt;=16]')\nsmall_text = page.find_all('text[size&lt;=8]')\n\n# Find text with specific font variant\n# (PDFs often use prefixes like 'AAAAAB+' in font names)\nvariant_text = page.find_all('text[font-variant=\"AAAAAB\"]')\n\n# Combine font attributes\nimportant_text = page.find_all('text[font-variant=\"AAAAAB\"][size&gt;=12]:bold')\n</code></pre> <p>For a deep dive into PDF fonts, see the Understanding PDF Fonts guide.</p>"},{"location":"element-selection/#element-navigation-methods","title":"Element Navigation Methods","text":"<p>Once you've found an element, you can navigate to related elements:</p> <pre><code># Find a starting element\nelement = page.find('text:contains(\"Introduction\")')\n\n# Get the next element in reading order\nnext_element = element.next()  # Next element regardless of type\nnext_text = element.next('text')  # Next text element\nnext_bold = element.next('text:bold', limit=20)  # Next bold text within 20 elements\n\n# Get the previous element in reading order\nprev_element = element.prev()  # Previous element regardless of type\nprev_heading = element.prev('text[size&gt;=12]')  # Previous large text\n\n# Find the nearest element by Euclidean distance\nnearest_element = element.nearest('rect')  # Nearest rectangle\nnearest_with_limit = element.nearest('text:contains(\"Table\")', max_distance=100)\n</code></pre> <p>These navigation methods respect exclusion zones and can be used with any selector.</p>"},{"location":"element-selection/#next-steps","title":"Next Steps","text":"<p>Now that you know how to find elements, try these topics:</p> <ul> <li>Extracting Text</li> <li>Working with Regions</li> <li>Visual Debugging</li> <li>PDF Extraction Challenges</li> <li>Understanding PDF Fonts</li> </ul>"},{"location":"explanations/","title":"PDF Explanations","text":"<p>This section goes beyond \"how-to\" guides to explain the deeper aspects of PDF processing and challenging scenarios you might encounter. These explanations help you understand why certain approaches work better than others.</p>"},{"location":"explanations/#available-explanations","title":"Available Explanations","text":""},{"location":"explanations/#pdf-extraction-challenges","title":"PDF Extraction Challenges","text":"<p>Why PDFs are hard to extract from and strategies for handling common problems like jumbled text order, mixed columns, corrupted fonts, and more.</p>"},{"location":"explanations/#understanding-fonts-in-pdfs","title":"Understanding Fonts in PDFs","text":"<p>A deep dive into how fonts work in PDFs, what those strange font names like \"ABCDEF+Arial\" mean, and how to handle font-related extraction issues.</p>"},{"location":"explanations/#ocr-challenges-and-solutions","title":"OCR Challenges and Solutions","text":"<p>The ins and outs of Optical Character Recognition, comparing OCR engines, and techniques for getting better results from problematic documents.</p>"},{"location":"explanations/#tips-for-approaching-pdf-problems","title":"Tips for Approaching PDF Problems","text":"<ol> <li>Start simple, then add complexity: Try the basic approaches before diving into complex solutions</li> <li>Visualize, don't guess: Use <code>highlight()</code> and <code>to_image()</code> to see what's happening</li> <li>Mix and match methods: Combine different extraction techniques for better results</li> <li>Test on samples: PDF extraction methods that work well on one document might fail on another</li> <li>Know when to use OCR: Sometimes OCR is necessary even when PDFs appear to have text</li> </ol>"},{"location":"explanations/#further-reading","title":"Further Reading","text":"<ul> <li>Element Selection: How to find specific elements in PDFs</li> <li>Text Extraction: Methods for extracting clean text</li> <li>Document QA: Ask questions directly to your documents</li> </ul>"},{"location":"explanations/ocr-challenges/","title":"OCR Challenges and Solutions","text":"<p>OCR (Optical Character Recognition) seems simple in concept\u2014turn images of text into actual text\u2014but it's full of interesting challenges. This guide covers common OCR problems and how to solve them.</p>"},{"location":"explanations/ocr-challenges/#when-do-you-need-ocr","title":"When Do You Need OCR?","text":"<p>You'll need OCR in several common scenarios:</p> <ol> <li>Scanned documents: The obvious case\u2014documents that were printed and scanned.</li> <li>Image-only PDFs: PDFs created from images or scans without text layers.</li> <li>Protected PDFs: Some PDFs have security settings that prevent text extraction.</li> <li>Problematic fonts: When fonts are embedded incorrectly or have unusual encoding.</li> </ol>"},{"location":"explanations/ocr-challenges/#how-ocr-works-the-short-version","title":"How OCR Works (The Short Version)","text":"<p>OCR generally follows these steps:</p> <ol> <li>Preprocessing: Adjust the image (binarization, deskewing, noise removal)</li> <li>Text detection: Find where the text is located in the image</li> <li>Character recognition: Identify individual characters in those regions</li> <li>Post-processing: Correct errors using dictionaries or language models</li> </ol> <p>Different OCR engines handle these steps in different ways, which is why they perform differently on various documents.</p>"},{"location":"explanations/ocr-challenges/#ocr-engines-compared","title":"OCR Engines Compared","text":"<p>Natural PDF supports different OCR engines, each with strengths and weaknesses:</p>"},{"location":"explanations/ocr-challenges/#easyocr","title":"EasyOCR","text":"<p>Strengths: - Simple to use and configure - Good support for European languages - Reasonable performance on clean documents</p> <p>Weaknesses: - Slower than PaddleOCR - Struggles with complex layouts - Less accurate on small or low-contrast text</p>"},{"location":"explanations/ocr-challenges/#paddleocr","title":"PaddleOCR","text":"<p>Strengths: - Fast processing - Excellent performance on many languages - Better with complex layouts and small text - More accurate in many real-world scenarios</p> <p>Weaknesses: - More complex parameter tuning - Larger model files</p>"},{"location":"explanations/ocr-challenges/#common-ocr-problems-and-solutions","title":"Common OCR Problems and Solutions","text":""},{"location":"explanations/ocr-challenges/#1-low-image-quality","title":"1. Low Image Quality","text":"<p>Problem: Blurry, low-resolution, or noisy images lead to poor OCR results.</p> <p>Solution: <pre><code># Increase resolution when generating the image for OCR\npage.apply_ocr(resolution=300)  # Default is 200 DPI\n\n# For noisy images, adjust preprocessing parameters\npage.apply_ocr(\n    text_threshold=0.6,  # Text detection confidence (default: 0.7)\n    low_text=0.3,        # Text low-bound score (default: 0.4)\n    link_threshold=0.3   # Link confidence threshold (default: 0.4)\n)\n</code></pre></p>"},{"location":"explanations/ocr-challenges/#2-rotated-or-skewed-text","title":"2. Rotated or Skewed Text","text":"<p>Problem: Text that isn't perfectly horizontal can cause OCR to fail.</p> <p>Solution: <pre><code># Enable text rotation detection in PaddleOCR\npdf = PDF('skewed_document.pdf', \n          ocr_engine='paddleocr',\n          ocr={\n              'enabled': True,\n              'use_angle_cls': True  # Detect text direction\n          })\n</code></pre></p>"},{"location":"explanations/ocr-challenges/#3-mixed-languages","title":"3. Mixed Languages","text":"<p>Problem: Documents with multiple languages confuse single-language OCR models.</p> <p>Solution: <pre><code># Specify multiple languages\npdf = PDF('multilingual.pdf', ocr={\n    'enabled': True,\n    'languages': ['en', 'fr', 'de']  # English, French, German\n})\n\n# For Asian languages mixed with others, PaddleOCR often works better\npdf = PDF('mixed_languages.pdf', \n          ocr_engine='paddleocr',\n          ocr={\n              'enabled': True,\n              'languages': ['en', 'zh', 'ja']  # English, Chinese, Japanese\n          })\n</code></pre></p>"},{"location":"explanations/ocr-challenges/#4-small-text","title":"4. Small Text","text":"<p>Problem: Tiny text often gets missed or misread by OCR.</p> <p>Solution: <pre><code># Increase image resolution for OCR\npage.apply_ocr(resolution=400)  # Higher resolution for small text\n\n# Adjust magnification ratio\npage.apply_ocr(mag_ratio=2.0)  # Default is 1.5\n</code></pre></p>"},{"location":"explanations/ocr-challenges/#5-complex-layouts","title":"5. Complex Layouts","text":"<p>Problem: Multi-column text, tables, and other complex layouts can confuse OCR.</p> <p>Solution: <pre><code># Use layout analysis first to detect regions\npage.analyze_layout()\n\n# Then apply OCR to specific regions\ntext_regions = page.find_all('region[type=plain-text]')\nfor region in text_regions:\n    region_text = region.extract_text(ocr=True)\n    print(region_text)\n</code></pre></p>"},{"location":"explanations/ocr-challenges/#6-low-ocr-confidence","title":"6. Low OCR Confidence","text":"<p>Problem: OCR returns text but with low confidence scores.</p> <p>Solution: <pre><code># Visualize confidence scores to identify problem areas\nocr_elements = page.apply_ocr()\nfor element in ocr_elements:\n    if element.confidence &lt; 0.5:\n        element.highlight(color=\"red\", label=f\"Low conf: {element.confidence:.2f}\")\n    else:\n        element.highlight(color=\"green\", label=f\"High conf: {element.confidence:.2f}\")\nimage = page.to_image(labels=True)\nimage\n\n# Filter by confidence\nhigh_confidence = page.find_all('text[source=ocr][confidence&gt;=0.7]')\nhigh_confidence_text = high_confidence.extract_text()\n</code></pre></p>"},{"location":"explanations/ocr-challenges/#when-ocr-isnt-working","title":"When OCR Isn't Working","text":"<p>If OCR is giving poor results even after tuning, try these approaches:</p> <ol> <li>Try a different engine: If EasyOCR isn't working well, try PaddleOCR and vice versa.</li> </ol> <pre><code># Switch engines to compare results\npdf_easy = PDF('document.pdf', ocr_engine='easyocr')\npdf_paddle = PDF('document.pdf', ocr_engine='paddleocr')\n\n# Extract with both and compare\neasy_text = pdf_easy.pages[0].extract_text(ocr=True)\npaddle_text = pdf_paddle.pages[0].extract_text(ocr=True)\n</code></pre> <ol> <li> <p>Pre-process the PDF: Sometimes converting the PDF to images externally and cleaning them up with tools like ImageMagick before OCRing can help.</p> </li> <li> <p>Focus on regions: Apply OCR to smaller, targeted regions rather than the whole page.</p> </li> </ol> <pre><code># Get just the important part of the page\nimportant_area = page.create_region(100, 200, 500, 600)\nimportant_text = important_area.extract_text(ocr=True)\n</code></pre> <ol> <li>Combine results: Use both native text extraction and OCR, then choose the better one.</li> </ol> <pre><code># Get both and compare\nnative_text = page.extract_text(ocr=False)\nocr_text = page.extract_text(ocr=True)\n\n# Choose the longer one (often the better extraction)\nfinal_text = native_text if len(native_text) &gt; len(ocr_text) else ocr_text\n</code></pre>"},{"location":"explanations/ocr-challenges/#the-document-qa-alternative","title":"The Document QA Alternative","text":"<p>Sometimes extracting perfect text isn't necessary. If you're looking to answer questions about a document, Document QA might work better:</p> <pre><code># Ask questions directly rather than extracting text first\nresult = pdf.ask(\"What was the total revenue in 2023?\")\nif result.get(\"found\", False):\n    print(f\"Answer: {result['answer']}\")\n</code></pre> <p>Document QA uses the image along with text positions to understand content, so it can often handle cases where OCR alone struggles.</p>"},{"location":"explanations/ocr-challenges/#why-document-qa-can-be-better-than-just-using-an-llm","title":"Why Document QA Can Be Better Than Just Using an LLM","text":"<p>If you've thought \"why not just feed the text to ChatGPT?\", there are good reasons to use Document QA instead:</p> <ol> <li>No hallucinations: Document QA only returns information actually present in the document</li> <li>Visual context: It understands layout, so it can interpret tables and know when content is in headers vs body text</li> <li>Shows you the source: You can see exactly where the answer came from</li> <li>Better with complex layouts: It understands when text is arranged in columns, tables, or other structures</li> </ol>"},{"location":"explanations/ocr-challenges/#further-reading","title":"Further Reading","text":"<ul> <li>OCR Integration in Natural PDF</li> <li>Document QA</li> <li>Layout Analysis</li> </ul>"},{"location":"explanations/pdf-extraction-challenges/","title":"PDF Extraction Challenges","text":"<p>If you've ever tried to extract content from PDFs, you know it can be surprisingly difficult. PDFs look simple when viewed, but under the hood, they're complex beasts. This guide explains common PDF extraction problems and how to solve them.</p>"},{"location":"explanations/pdf-extraction-challenges/#why-pdf-extraction-is-hard","title":"Why PDF Extraction Is Hard","text":"<p>PDFs were designed for reliable printing and viewing, not for data extraction. They're essentially digital layouts of printed pages, with these complicating factors:</p> <ol> <li>No semantic structure: PDFs don't inherently know what's a heading, paragraph, or table</li> <li>Position-based layout: Text is placed at specific coordinates, not in a flow</li> <li>No guaranteed reading order: What looks like sequential paragraphs might be scattered in the file</li> <li>Complex text encoding: Custom fonts, character mappings, and compression schemes</li> <li>Mixed content types: Text, images, vector graphics, and forms all combined</li> </ol>"},{"location":"explanations/pdf-extraction-challenges/#common-extraction-problems","title":"Common Extraction Problems","text":""},{"location":"explanations/pdf-extraction-challenges/#text-comes-out-in-the-wrong-order","title":"Text Comes Out in the Wrong Order","text":"<p>Problem: Extracted text is jumbled, with paragraphs or sentences out of sequence.</p> <p>Solution: Natural PDF sorts elements in reading order by default:</p> <pre><code># Reading order is enabled by default\npdf = PDF(\"document.pdf\", reading_order=True)\n\n# Extract text in reading order\ntext = page.extract_text()\n</code></pre>"},{"location":"explanations/pdf-extraction-challenges/#headers-and-footers-mix-with-content","title":"Headers and Footers Mix with Content","text":"<p>Problem: Page numbers, document titles, and other repeating elements appear throughout extracted text.</p> <p>Solution: Use exclusion zones to remove them:</p> <pre><code># Exclude the header\nheader = page.find('text:contains(\"CONFIDENTIAL\")').above()\npage.add_exclusion(header)\n\n# Exclude the footer\nfooter = page.find('text:contains(\"Page\")').below()\npage.add_exclusion(footer)\n\n# Extract text without header/footer\nclean_text = page.extract_text()  # Exclusions applied by default\n</code></pre>"},{"location":"explanations/pdf-extraction-challenges/#columns-get-mixed-together","title":"Columns Get Mixed Together","text":"<p>Problem: Multi-column layouts (like in newspapers or academic papers) get merged into a confusing mess.</p> <p>Solution: Use layout analysis to detect and process columns separately:</p> <pre><code># Detect regions including columns\npage.analyze_layout()\n\n# Find text regions (often column blocks)\ntext_blocks = page.find_all('region[type=plain-text]')\n\n# Process each text block separately\nfor i, block in enumerate(text_blocks):\n    block_text = block.extract_text()\n    print(f\"Text Block {i+1}:\\n{block_text}\\n\")\n</code></pre>"},{"location":"explanations/pdf-extraction-challenges/#tables-lose-their-structure","title":"Tables Lose Their Structure","text":"<p>Problem: Tables become unstructured text blocks, losing row/column relationships.</p> <p>Solution: Use table-specific extraction:</p> <pre><code># Detect tables with layout analysis\npage.analyze_layout(model=\"tatr\")  # Table Transformer model\n\n# Find and extract tables\ntables = page.find_all('region[type=table]')\nfor i, table in enumerate(tables):\n    table_data = table.extract_table()\n    print(f\"Table {i+1}:\")\n    for row in table_data:\n        print(row)\n</code></pre>"},{"location":"explanations/pdf-extraction-challenges/#missing-or-garbled-text","title":"Missing or Garbled Text","text":"<p>Problem: Some text appears as gibberish or is completely missing.</p> <p>Solution: This is often a font issue - try OCR:</p> <pre><code># Try OCR instead of native extraction\ntext = page.extract_text(ocr=True)\n\n# For pages with mixed issues, compare both approaches\nnative_text = page.extract_text(ocr=False)\nocr_text = page.extract_text(ocr=True)\n\n# Use the better result (often the longer one)\nfinal_text = native_text if len(native_text) &gt; len(ocr_text) else ocr_text\n</code></pre>"},{"location":"explanations/pdf-extraction-challenges/#hyphenation-at-line-breaks","title":"Hyphenation at Line Breaks","text":"<p>Problem: Words hyphenated at line breaks appear with hyphens in the extracted text.</p> <p>Solution: Use post-processing to handle this:</p> <pre><code>import re\n\n# Extract text\ntext = page.extract_text()\n\n# Remove hyphenation at line breaks\nclean_text = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', text)\n</code></pre>"},{"location":"explanations/pdf-extraction-challenges/#problematic-pdfs","title":"Problematic PDFs","text":"<p>Some PDFs are particularly challenging:</p> <ol> <li>Scanned documents: These are just images with no actual text</li> <li>Protected PDFs: Security settings can prevent text extraction</li> <li>Corrupted PDFs: Damaged files might not open properly</li> <li>Complex layouts: Magazines, brochures with text overlapping images</li> </ol> <p>Solution: Use a combination of approaches:</p> <pre><code>try:\n    # Try native extraction first\n    text = page.extract_text()\n\n    # If too little text is found, fall back to OCR\n    if len(text.strip()) &lt; 100:  # Arbitrary threshold\n        text = page.extract_text(ocr=True)\n\nexcept Exception as e:\n    print(f\"Error processing page: {e}\")\n    # Fall back to OCR\n    text = page.extract_text(ocr=True)\n</code></pre>"},{"location":"explanations/pdf-extraction-challenges/#region-based-extraction-a-better-approach","title":"Region-Based Extraction: A Better Approach","text":"<p>Instead of treating PDFs as one big blob of text, region-based extraction often works better:</p> <pre><code># Get all heading-like elements\nheadings = page.find_all('text[size&gt;=12]:bold')\n\n# Extract content under each heading\nfor heading in headings:\n    # Get content until the next heading\n    content_region = heading.below(until='text[size&gt;=12]:bold', include_until=False)\n    content = content_region.extract_text()\n\n    print(f\"Section: {heading.text}\")\n    print(content)\n    print(\"-\" * 40)\n</code></pre>"},{"location":"explanations/pdf-extraction-challenges/#alternative-direct-question-answering","title":"Alternative: Direct Question Answering","text":"<p>Sometimes, extracting perfect text isn't necessary if you just need specific information:</p> <pre><code># Ask questions directly\nresult = pdf.ask(\"What was the total revenue reported for 2023?\")\nif result.get(\"found\", False):\n    print(f\"Answer: {result['answer']}\")\n    print(f\"Confidence: {result['confidence']:.2f}\")\n</code></pre>"},{"location":"explanations/pdf-extraction-challenges/#common-strategies-for-better-extraction","title":"Common Strategies for Better Extraction","text":"<ol> <li>Divide and conquer: Work with small regions rather than the whole page</li> <li>Use visual clues: Find prominent visual elements (like headings) and use them to navigate</li> <li>Try multiple methods: Different approaches work better for different documents</li> <li>Verify the results: Don't assume extraction is perfect; spot-check the results</li> </ol>"},{"location":"explanations/pdf-extraction-challenges/#benefits-of-natural-pdf-vs-raw-pdfplumber","title":"Benefits of Natural PDF vs. Raw PDFPlumber","text":"<p>Natural PDF makes PDF extraction more intuitive by:</p> <ol> <li>Adding reading order: Elements are sorted into logical reading order</li> <li>Providing spatial navigation: Methods like <code>above()</code>, <code>below()</code>, and <code>until()</code></li> <li>Using CSS-like selectors: Find elements with simple, readable queries</li> <li>Integrating OCR: Built-in OCR capabilities for scanned documents</li> <li>Supporting layout analysis: AI-powered document structure detection</li> <li>Offering visualization: Debug what's happening with visual highlights</li> <li>Handling exclusions: Easily remove headers, footers, and other unwanted content</li> </ol>"},{"location":"explanations/pdf-extraction-challenges/#further-reading","title":"Further Reading","text":"<ul> <li>Understanding PDF Fonts</li> <li>OCR Challenges and Solutions</li> <li>Working with regions</li> <li>Document Layout Analysis</li> </ul>"},{"location":"explanations/pdf-fonts/","title":"Understanding Fonts in PDFs","text":"<p>Fonts in PDFs can be tricky. If you've extracted text and gotten strange characters or missing content, font issues are often the culprit. This guide explains how PDF fonts work and how to handle common problems you might encounter.</p>"},{"location":"explanations/pdf-fonts/#how-fonts-work-in-pdfs","title":"How Fonts Work in PDFs","text":"<p>PDFs can include fonts in several ways:</p> <ol> <li>Standard Fonts: A set of 14 standard fonts that all PDF viewers support (like Times, Helvetica, Courier)</li> <li>Embedded Fonts: Fonts included directly within the PDF file</li> <li>Referenced Fonts: Fonts referenced by name but expected to be available on the user's system</li> <li>Subset Fonts: Embedded fonts containing only the characters actually used in the document</li> </ol>"},{"location":"explanations/pdf-fonts/#font-naming-in-pdfs","title":"Font Naming in PDFs","text":"<p>One of the most confusing aspects of PDF fonts is their naming. You'll often see font names like <code>ABCDEF+Arial-Bold</code>. This strange format has two components:</p> <ul> <li>Prefix (ABCDEF+): A unique identifier for a font subset</li> <li>Base Name (Arial-Bold): The actual font family and style</li> </ul> <p>The prefix is generated during PDF creation and helps distinguish between different subsets of the same font. For example, a document might have:</p> <ul> <li><code>ABCDEF+Arial-Bold</code> containing only the characters \"Hello\"</li> <li><code>XYZPQR+Arial-Bold</code> containing only the characters \"World\"</li> </ul> <p>Both are subsets of Arial Bold, but they contain different character sets to minimize file size.</p>"},{"location":"explanations/pdf-fonts/#diagnosing-font-issues-with-natural-pdf","title":"Diagnosing Font Issues with Natural PDF","text":""},{"location":"explanations/pdf-fonts/#listing-all-fonts-in-a-document","title":"Listing All Fonts in a Document","text":"<p>Natural PDF can help you understand what fonts are used in your document:</p> <pre><code>from natural_pdf import PDF\nfrom collections import defaultdict\n\npdf = PDF(\"document.pdf\")\n\n# Create a dictionary to store fonts\nfonts = defaultdict(int)\n\n# Collect all fonts from all pages\nfor page in pdf.pages:\n    text_elements = page.find_all('text')\n    for elem in text_elements:\n        fonts[elem.fontname] = fonts.get(elem.fontname, 0) + 1\n\n# Print the fonts and their usage count\nprint(\"Fonts used in document:\")\nfor font, count in sorted(fonts.items(), key=lambda x: x[1], reverse=True):\n    print(f\"- {font}: {count} occurrences\")\n\n# Analyze font variants (subsets)\nvariants = defaultdict(set)\nfor font in fonts.keys():\n    if '+' in font:\n        prefix, base = font.split('+', 1)\n        variants[base].add(prefix)\n\nprint(\"\\nFont variants:\")\nfor base, prefixes in variants.items():\n    print(f\"- {base}: {len(prefixes)} variants ({', '.join(prefixes)})\")\n</code></pre>"},{"location":"explanations/pdf-fonts/#finding-elements-with-specific-font-variants","title":"Finding Elements with Specific Font Variants","text":"<p>You can use Natural PDF's selectors to find text with specific font variants:</p> <pre><code># Find all elements using a specific font variant\narial_bold_variant = page.find_all('text[fontname*=\"ABCDEF+Arial-Bold\"]')\n\n# Or use the font-variant attribute (which extracts the prefix)\nvariant_elements = page.find_all('text[font-variant=\"ABCDEF\"]')\n\n# Find all elements using the base font, regardless of variant\nall_arial_bold = page.find_all('text[fontname*=\"Arial-Bold\"]')\n</code></pre>"},{"location":"explanations/pdf-fonts/#common-font-challenges-in-pdfs","title":"Common Font Challenges in PDFs","text":""},{"location":"explanations/pdf-fonts/#1-font-subsets-and-text-extraction","title":"1. Font Subsets and Text Extraction","text":"<p>When PDFs use font subsets, some characters might not be properly mapped, leading to incorrect text extraction. You might encounter:</p> <ul> <li>Gibberish text (<code>\"\u00d0\u00a1\u017d\u0160\"</code> instead of \"Hello\")</li> <li>Missing characters (appearing as \u25a1 or ?)</li> <li>Completely incorrect character mappings</li> </ul> <p>Natural PDF helps handle this:</p> <pre><code># For PDFs with font encoding issues, OCR can be more reliable\npdf = PDF(\"problematic_document.pdf\", ocr=\"auto\")\n\n# Extract text - will use OCR if native text extraction fails\ntext = pdf.pages[0].extract_text()\n</code></pre>"},{"location":"explanations/pdf-fonts/#2-identifying-text-by-visual-appearance-vs-font-name","title":"2. Identifying Text by Visual Appearance vs Font Name","text":"<p>Sometimes you want to find text that looks visually similar, regardless of how the font is technically named:</p> <pre><code># Group text by visual properties (size, weight, etc.)\ntext_styles = page.analyze_text_styles()\n\n# Check the properties of each style\nfor style_name, elements in text_styles.items():\n    if elements:\n        example = elements[0]\n        print(f\"{style_name}:\")\n        print(f\"  Font: {example.fontname}\")\n        print(f\"  Size: {example.size}\")\n        print(f\"  Bold: {example.bold}\")\n        print(f\"  Italic: {example.italic}\")\n        print(f\"  Example: {example.text[:20]}...\")\n</code></pre>"},{"location":"explanations/pdf-fonts/#3-font-color-handling","title":"3. Font Color Handling","text":"<p>PDFs represent colors in different ways. Natural PDF normalizes these for easy use:</p> <pre><code># Find text with specific colors\nred_text = page.find_all('text[color~=red]')\nblue_text = page.find_all('text[color~=blue]')\n\n# Check the color of a specific element\nelement = page.find('text:contains(\"Important\")')\nif element:\n    print(f\"Color: {element.color}\")  # Returns as RGB tuple\n\n    # Visualize the color\n    element.highlight(label=f\"Color: {element.color}\")\n    image = page.to_image()\n    image\n</code></pre>"},{"location":"explanations/pdf-fonts/#font-embedding-and-accessibility","title":"Font Embedding and Accessibility","text":"<p>Understanding font embedding is important for PDF accessibility and preservation:</p> <ul> <li>Fully embedded fonts: The PDF contains all font data needed to render the text</li> <li>Subset embedded fonts: Only the characters used in the document are embedded</li> <li>Referenced fonts: The PDF relies on the viewing system having the font installed</li> </ul> <p>Natural PDF can help you determine if fonts might cause problems:</p> <pre><code># Advanced: Check for non-embedded fonts that might cause issues\nfrom collections import Counter\n\nnon_embedded_fonts = Counter()\n\nfor page in pdf.pages:\n    text_elements = page.find_all('text')\n    for elem in text_elements:\n        # Use pdfplumber's native font info\n        font_dict = elem._obj.get('fontname', '')\n\n        # If a font doesn't contain a '+', it might not be embedded\n        if '+' not in font_dict and font_dict not in ['Times-Roman', 'Helvetica', 'Courier']:\n            non_embedded_fonts[font_dict] += 1\n\nif non_embedded_fonts:\n    print(\"Warning: Document contains possibly non-embedded fonts:\")\n    for font, count in non_embedded_fonts.most_common():\n        print(f\"- {font}: {count} occurrences\")\n</code></pre>"},{"location":"explanations/pdf-fonts/#when-to-use-ocr-instead-of-native-text-extraction","title":"When to Use OCR Instead of Native Text Extraction","text":"<p>Sometimes, even with embedded fonts, text extraction may fail due to:</p> <ol> <li>Custom encoding tables</li> <li>Security features in the PDF</li> <li>Non-standard fonts with incorrect character mappings</li> <li>Text rendered as vector graphics or images</li> </ol> <p>In these cases, OCR might yield better results:</p> <pre><code># Compare native extraction vs OCR\nnative_text = page.extract_text(ocr=False)\nocr_text = page.extract_text(ocr=True)\n\nprint(f\"Native extraction: {len(native_text)} characters\")\nprint(f\"OCR extraction: {len(ocr_text)} characters\")\n\n# If lengths differ dramatically, you may have font encoding issues\nif abs(len(native_text) - len(ocr_text)) &gt; len(native_text) * 0.5:\n    print(\"Significant difference detected - possible font encoding issues\")\n\n    # View sample of both for comparison\n    print(\"\\nNative sample:\", native_text[:100])\n    print(\"\\nOCR sample:\", ocr_text[:100])\n</code></pre>"},{"location":"explanations/pdf-fonts/#best-practices-for-font-handling","title":"Best Practices for Font Handling","text":"<ol> <li>Check font coverage first: Use the font analysis example above to understand what fonts your document uses</li> <li>Use font-variant in selectors: When you need to target specific variants of a font</li> <li>Try OCR when text extraction fails: If you see gibberish or missing text, OCR may give better results</li> <li>Group by visual appearance: Use <code>analyze_text_styles()</code> to find text that looks similar, regardless of technical font names</li> </ol> <p>Understanding font handling in PDFs will help you extract text more effectively and handle edge cases that often arise in real-world documents.</p>"},{"location":"explanations/pdf-fonts/#further-reading","title":"Further Reading","text":"<ul> <li>Understanding Font Naming in PDFs</li> <li>PDF Specification - Font Resources</li> <li>OCR Integration in Natural PDF</li> </ul>"},{"location":"installation/","title":"Getting Started with Natural PDF","text":"<p>Let's get Natural PDF installed and run your first extraction.</p>"},{"location":"installation/#installation","title":"Installation","text":"<pre><code>pip install natural-pdf\n</code></pre>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>Natural PDF has modular dependencies for different features:</p> <pre><code># Install OCR support with EasyOCR\npip install natural-pdf[easyocr]\n\n# Install PaddleOCR support\npip install natural-pdf[paddle]\n\n# Install all optional dependencies\npip install natural-pdf[all]\n</code></pre>"},{"location":"installation/#your-first-pdf-extraction","title":"Your First PDF Extraction","text":"<p>Here's a quick example to make sure everything is working:</p> <pre><code>from natural_pdf import PDF\n\n# Open a PDF\npdf = PDF('your_document.pdf')\n\n# Get the first page\npage = pdf.pages[0]\n\n# Extract all text\ntext = page.extract_text()\nprint(text)\n\n# Find something specific\ntitle = page.find('text:bold')\nif title:\n    print(f\"Found title: {title.text}\")\n</code></pre>"},{"location":"installation/#whats-next","title":"What's Next?","text":"<p>Now that you have Natural PDF installed, you can:</p> <ul> <li>Learn to navigate PDFs</li> <li>Explore how to select elements</li> <li>See how to extract text</li> </ul>"},{"location":"layout-analysis/","title":"Document Layout Analysis","text":"<p>Natural PDF includes document layout analysis capabilities that can automatically detect the structure of your documents, including headings, paragraphs, tables, and other elements.</p>"},{"location":"layout-analysis/#layout-analysis-models-comparison","title":"Layout Analysis Models Comparison","text":"<p>Natural PDF supports multiple layout analysis models:</p> Feature YOLO Model PaddleOCR Layout Table Transformer (TATR) Primary Focus General document structure Text-oriented layout Table structure Region Types 10+ types (titles, text, tables, figures, etc.) 5 types (text, title, list, table, figure) 4 types (table, row, column, header) Table Detection Detects tables as a unit Detects tables as a unit Detailed table structure Speed Fast Medium Slower OCR Integration Works independently Integrated with PaddleOCR Works independently Best For General document analysis Text-heavy documents Table extraction Default in Library Yes No No"},{"location":"layout-analysis/#model-selection-guide","title":"Model Selection Guide","text":"<pre><code>graph LR\n    A{Need?} --&gt; B{Tables?}\n    B --&gt;|Detailed structure| C[TATR]\n    B --&gt;|Just boundaries| D[YOLO]\n    B --&gt;|No tables| E{Document type?}\n\n    E --&gt;|General| D\n    E --&gt;|Text-heavy| F[PaddleOCR]\n\n    style C fill:#bbf,stroke:#333\n    style D fill:#bfb,stroke:#333\n    style F fill:#fbf,stroke:#333</code></pre>"},{"location":"layout-analysis/#available-layout-models","title":"Available Layout Models","text":"<p>Natural PDF supports multiple layout analysis models:</p> <ol> <li>YOLO (default) - General document layout detection:</li> <li><code>title</code>: Document titles and headings</li> <li><code>plain-text</code>: Regular paragraph text</li> <li><code>table</code>: Tabular data</li> <li><code>figure</code>: Images and figures</li> <li><code>figure_caption</code>: Captions for figures</li> <li><code>table_caption</code>: Captions for tables</li> <li> <p>And several other specialized region types</p> </li> <li> <p>Table Transformer (TATR) - Detailed table structure analysis:</p> </li> <li><code>table</code>: The complete table</li> <li><code>table-row</code>: Individual rows</li> <li><code>table-column</code>: Individual columns</li> <li><code>table-column-header</code>: Column headers</li> </ol>"},{"location":"layout-analysis/#basic-layout-analysis","title":"Basic Layout Analysis","text":"<p>To analyze the layout of a document:</p> <pre><code>from natural_pdf import PDF\n\npdf = PDF('document.pdf')\npage = pdf.pages[0]\n\n# Analyze the layout\npage.analyze_layout()\n\n# Find all detected regions\nregions = page.find_all('region')\nprint(f\"Found {len(regions)} regions\")\n\n# Highlight all detected regions\npage.highlight_layout()\npage.save_image(\"layout_detection.png\")\n</code></pre>"},{"location":"layout-analysis/#finding-specific-region-types","title":"Finding Specific Region Types","text":"<p>You can find specific types of regions:</p> <pre><code># Find titles/headings\ntitles = page.find_all('region[type=title]')\n\n# Find paragraphs (plain text)\nparagraphs = page.find_all('region[type=plain-text]')\n\n# Find tables\ntables = page.find_all('region[type=table]')\n\n# Find figures\nfigures = page.find_all('region[type=figure]')\n</code></pre>"},{"location":"layout-analysis/#working-with-layout-regions","title":"Working with Layout Regions","text":"<p>Once you have detected regions, you can work with them like any other region:</p> <pre><code># Extract text from a table region\nif tables:\n    table = tables[0]\n    table_text = table.extract_text()\n    print(f\"Table content: {table_text}\")\n\n    # Highlight the table\n    table.highlight(color=(0, 0, 1, 0.2), label=\"Table\")\n\n    # Get all text elements within the table\n    table_elements = table.find_all('text')\n</code></pre>"},{"location":"layout-analysis/#layout-models","title":"Layout Models","text":"<p>Natural PDF supports multiple layout detection models:</p> <pre><code># Use the default YOLO model\npage.analyze_layout()\n\n# Use the PaddleOCR layout model\npage.analyze_layout(model=\"paddle\")\n\n# Use the Table Transformer model for table structure\npage.analyze_layout(model=\"tatr\")\n</code></pre>"},{"location":"layout-analysis/#controlling-detection-confidence","title":"Controlling Detection Confidence","text":"<p>You can control the confidence threshold for detection:</p> <pre><code># Use a higher confidence threshold for more reliable detections\npage.analyze_layout(confidence=0.5)  # Only regions with 50%+ confidence\n\n# Use a lower threshold to detect more regions\npage.analyze_layout(confidence=0.2)  # More regions, but might include some false positives\n</code></pre>"},{"location":"layout-analysis/#visualizing-layout-detection","title":"Visualizing Layout Detection","text":"<p>You can visualize the detected layout:</p> <pre><code># Highlight layout regions\npage.highlight_layout()\npage.save_image(\"layout_highlights.png\")\n\n# Highlight with confidence scores\npage.highlight_layout(include_attrs=['confidence'])\npage.save_image(\"layout_with_confidence.png\")\n\n# Color-code by confidence level\nhigh_conf = page.find_all('region[confidence&gt;=0.8]')\nmed_conf = page.find_all('region[confidence&gt;=0.5][confidence&lt;0.8]')\nlow_conf = page.find_all('region[confidence&lt;0.5]')\n\nhigh_conf.highlight(color=(0, 1, 0, 0.3), label=\"High Confidence\")\nmed_conf.highlight(color=(1, 1, 0, 0.3), label=\"Medium Confidence\")\nlow_conf.highlight(color=(1, 0, 0, 0.3), label=\"Low Confidence\")\n\n# Save the visualization\npage.save_image(\"confidence_levels.png\", labels=True)\n</code></pre>"},{"location":"layout-analysis/#table-structure-detection","title":"Table Structure Detection","text":"<p>The TATR (Table Transformer) model can detect detailed table structure:</p> <pre><code># Analyze table structure\npage.analyze_layout(model=\"tatr\")\n\n# Find table structure elements\ntables = page.find_all('region[type=table]')\nrows = page.find_all('region[type=table-row]')\ncolumns = page.find_all('region[type=table-column]')\nheaders = page.find_all('region[type=table-column-header]')\n\n# Highlight table structure\ntables.highlight(color=(0, 0, 1, 0.2), label=\"Tables\")\nrows.highlight(color=(1, 0, 0, 0.2), label=\"Rows\")\ncolumns.highlight(color=(0, 1, 0, 0.2), label=\"Columns\")\nheaders.highlight(color=(0.5, 0, 0.5, 0.2), label=\"Headers\")\n\n# Save the visualization\npage.save_image(\"table_structure.png\", labels=True)\n</code></pre>"},{"location":"layout-analysis/#combined-layout-analysis","title":"Combined Layout Analysis","text":"<p>You can combine multiple models for more comprehensive analysis:</p> <pre><code># Clear any existing layout regions\npage.clear_layout_regions()\n\n# First detect general layout with YOLO model\npage.analyze_layout(model=\"yolo\", existing=\"replace\")\n\n# Then detect table structure with TATR model\npage.analyze_layout(model=\"tatr\", existing=\"append\")\n\n# Find regions from each model\nyolo_regions = page.find_all('region[model=yolo]')\ntatr_regions = page.find_all('region[model=tatr]')\n\n# Highlight regions by model\nyolo_regions.highlight(color=(0, 0, 1, 0.2), label=\"YOLO Regions\")\ntatr_regions.highlight(color=(1, 0, 0, 0.2), label=\"TATR Regions\")\n</code></pre>"},{"location":"layout-analysis/#ocr-layout-analysis","title":"OCR + Layout Analysis","text":"<p>For scanned documents, you can combine OCR with layout analysis:</p> <pre><code># Enable OCR\npdf = PDF('scanned_document.pdf', ocr=True)\npage = pdf.pages[0]\n\n# First apply OCR\npage.apply_ocr()\n\n# Then analyze layout\npage.analyze_layout()\n\n# Find text in detected regions\ntitle_region = page.find('region[type=title]')\nif title_region:\n    title_text = title_region.extract_text()\n    print(f\"Title: {title_text}\")\n</code></pre>"},{"location":"layout-analysis/#region-attributes","title":"Region Attributes","text":"<p>Layout regions have additional attributes you can access:</p> <pre><code>region = page.find('region')\nif region:\n    # Region type (title, table, paragraph, etc.)\n    region_type = region.region_type\n\n    # Confidence score (0-1)\n    confidence = region.confidence\n\n    # Model used for detection\n    model = region.model\n\n    # Print region info\n    print(f\"Region type: {region_type}, Confidence: {confidence:.2f}, Model: {model}\")\n</code></pre>"},{"location":"layout-analysis/#region-images","title":"Region Images","text":"<p>You can extract images of detected regions:</p> <pre><code># Find a table region\ntable = page.find('region[type=table]')\nif table:\n    # Extract an image of just the table\n    table_image = table.to_image(resolution=150)\n    table.save_image(\"table.png\")\n</code></pre>"},{"location":"layout-analysis/#table-structure-detection_1","title":"Table Structure Detection","text":"<p>For detailed table analysis, use the Table Transformer (TATR) model:</p> <pre><code># Analyze table structure\npage.analyze_layout(model=\"tatr\")\n\n# Find table components\ntables = page.find_all('region[type=table]')\nrows = page.find_all('region[type=table-row]')\ncolumns = page.find_all('region[type=table-column]')\nheaders = page.find_all('region[type=table-column-header]')\n\n# Highlight the table structure\ntables.highlight(color=\"blue\", label=\"Tables\")\nrows.highlight(color=\"red\", label=\"Rows\")\ncolumns.highlight(color=\"green\", label=\"Columns\")\nheaders.highlight(color=\"purple\", label=\"Headers\")\n\n# Extract the table data\nif tables:\n    table_data = tables[0].extract_table(method=\"tatr\")\n    print(table_data)\n</code></pre> <p>For more details on table extraction, visit the Tables documentation.</p>"},{"location":"layout-analysis/#parameter-tuning-guide","title":"Parameter Tuning Guide","text":"<p>The right confidence threshold improves results:</p> Document Type Recommended Confidence Notes Clean, well-structured 0.5 - 0.7 Higher threshold for cleaner results Average quality 0.3 - 0.5 Balance between coverage and accuracy Poor quality/scanned 0.2 - 0.3 Lower threshold to catch more regions Mixed content 0.3 Good general-purpose starting point"},{"location":"layout-analysis/#next-steps","title":"Next Steps","text":"<p>With layout analysis, you can:</p> <ul> <li>Extract tables from your documents</li> <li>Ask questions about specific regions</li> <li>Work with regions for more precise extraction</li> <li>Learn about PDF extraction challenges</li> </ul>"},{"location":"ocr/","title":"OCR Integration","text":"<p>Natural PDF includes OCR (Optical Character Recognition) to extract text from scanned documents or images embedded in PDFs.</p>"},{"location":"ocr/#ocr-engine-comparison","title":"OCR Engine Comparison","text":"<p>Natural PDF supports multiple OCR engines:</p> Feature EasyOCR PaddleOCR Default in Library No Yes Performance Works better for most Western documents Excellent for Asian languages Speed Moderate Fast Memory Usage Higher Efficient Paragraph Detection Yes No Handwritten Text Better support Limited Small Text Moderate Good Custom Models Limited Fully supported When to Use Most general documents, handwritten text Asian languages, when speed is critical"},{"location":"ocr/#basic-ocr-usage","title":"Basic OCR Usage","text":"<p>To enable OCR:</p> <pre><code>from natural_pdf import PDF\n\n# Enable OCR when opening the PDF\npdf = PDF('scanned_document.pdf', ocr=True)\n\n# Extract text (OCR will be applied automatically)\ntext = pdf.pages[0].extract_text()\nprint(text)\n</code></pre>"},{"location":"ocr/#auto-ocr-mode","title":"Auto OCR Mode","text":"<p>In \"auto\" mode, OCR is only applied when necessary:</p> <pre><code># Enable auto OCR mode\npdf = PDF('mixed_document.pdf', ocr='auto')\n\n# OCR will only be applied to pages that need it\nfor page in pdf.pages:\n    text = page.extract_text()  # OCR applied only if page has little/no text\n    print(f\"Page {page.index + 1}: {len(text)} characters extracted\")\n</code></pre>"},{"location":"ocr/#ocr-configuration","title":"OCR Configuration","text":"<p>You can customize OCR settings:</p> <pre><code># Set OCR parameters\npdf = PDF('document.pdf', ocr={\n    'enabled': True,               # Enable OCR\n    'languages': ['en'],           # Language(s) to recognize\n    'min_confidence': 0.5,         # Minimum confidence threshold\n    'paragraph': True,             # Try to group words into paragraphs\n})\n\n# Extract text with OCR\ntext = pdf.pages[0].extract_text()\n</code></pre>"},{"location":"ocr/#multiple-languages","title":"Multiple Languages","text":"<p>OCR supports multiple languages:</p> <pre><code># Recognize English and Spanish text\npdf = PDF('multilingual.pdf', ocr={\n    'enabled': True,\n    'languages': ['en', 'es']\n})\n\n# Multiple languages with PaddleOCR\npdf = PDF('multilingual_document.pdf', \n          ocr_engine='paddleocr',\n          ocr={\n              'enabled': True,\n              'languages': ['zh', 'ja', 'ko', 'en']  # Chinese, Japanese, Korean, English\n          })\n</code></pre>"},{"location":"ocr/#applying-ocr-directly","title":"Applying OCR Directly","text":"<p>You can apply OCR to a page or region on demand:</p> <pre><code># Apply OCR to a page and get the OCR elements\nocr_elements = page.apply_ocr()\nprint(f\"Found {len(ocr_elements)} text elements via OCR\")\n\n# Apply OCR to a specific region\ntitle = page.find('text:contains(\"Title\")')\ncontent_region = title.below(height=300)\nregion_ocr_elements = content_region.apply_ocr()\n</code></pre>"},{"location":"ocr/#ocr-engines","title":"OCR Engines","text":"<p>You can choose between different OCR engines:</p> <pre><code># Use EasyOCR (default)\npdf = PDF('document.pdf', ocr_engine='easyocr')\n\n# Use PaddleOCR (often more accurate)\npdf = PDF('document.pdf', ocr_engine='paddleocr')\n\n# Configure PaddleOCR-specific parameters\npdf = PDF('document.pdf', \n          ocr_engine='paddleocr',\n          ocr={\n              'enabled': True,\n              'use_angle_cls': False,  # Disable text direction detection\n              'det_db_thresh': 0.3,    # Text detection threshold\n              'rec_batch_num': 6       # Recognition batch size\n          })\n</code></pre>"},{"location":"ocr/#finding-and-working-with-ocr-text","title":"Finding and Working with OCR Text","text":"<p>After applying OCR, work with the text just like regular text:</p> <pre><code># Find all OCR text elements\nocr_text = page.find_all('text[source=ocr]')\n\n# Find high-confidence OCR text\nhigh_conf = page.find_all('text[source=ocr][confidence&gt;=0.8]')\n\n# Extract text only from OCR elements\nocr_text_content = page.find_all('text[source=ocr]').extract_text()\n\n# Filter OCR text by content\nnames = page.find_all('text[source=ocr]:contains(\"Smith\")', case=False)\n</code></pre>"},{"location":"ocr/#visualizing-ocr-results","title":"Visualizing OCR Results","text":"<p>See OCR results to help debug issues:</p> <pre><code># Apply OCR \nocr_elements = page.apply_ocr()\n\n# Highlight all OCR elements\nfor element in ocr_elements:\n    # Color based on confidence\n    if element.confidence &gt;= 0.8:\n        color = \"green\"  # High confidence\n    elif element.confidence &gt;= 0.5:\n        color = \"yellow\"  # Medium confidence\n    else:\n        color = \"red\"  # Low confidence\n\n    element.highlight(color=color, label=f\"OCR ({element.confidence:.2f})\")\n\n# Get the visualization as an image\nimage = page.to_image(labels=True)\n# Just return the image in a Jupyter cell\nimage\n\n# Highlight only high-confidence elements\nhigh_conf = page.find_all('text[source=ocr][confidence&gt;=0.8]')\nhigh_conf.highlight(color=\"green\", label=\"High Confidence OCR\")\n</code></pre>"},{"location":"ocr/#ocr-debugging","title":"OCR Debugging","text":"<p>For troubleshooting OCR problems:</p> <pre><code># Create an interactive HTML debug report\npdf.debug_ocr(\"ocr_debug.html\")\n\n# Specify which pages to include\npdf.debug_ocr(\"ocr_debug.html\", pages=[0, 1, 2])\n</code></pre> <p>The debug report shows: - The original image - Text found with confidence scores - Boxes around each detected word - Options to sort and filter results</p>"},{"location":"ocr/#troubleshooting-ocr","title":"Troubleshooting OCR","text":"<p>Having problems with OCR? Our OCR Challenges and Solutions guide provides detailed information about:</p> <ul> <li>Comparing EasyOCR and PaddleOCR engines</li> <li>Fixing issues with low-quality scans</li> <li>Handling mixed languages and complex layouts</li> <li>Optimizing OCR parameters for better results</li> </ul>"},{"location":"ocr/#ocr-parameter-tuning","title":"OCR Parameter Tuning","text":""},{"location":"ocr/#parameter-recommendation-table","title":"Parameter Recommendation Table","text":"Issue Engine Parameter Recommended Value Effect Missing text EasyOCR <code>text_threshold</code> 0.1 - 0.3 (default: 0.7) Lower values detect more text but may increase false positives Missing text PaddleOCR <code>det_db_thresh</code> 0.1 - 0.3 (default: 0.3) Lower values detect more text areas Low quality scan EasyOCR <code>contrast_ths</code> 0.05 - 0.1 (default: 0.1) Lower values help with low contrast documents Low quality scan PaddleOCR <code>det_limit_side_len</code> 1280 - 2560 (default: 960) Higher values improve detail detection Accuracy vs. speed EasyOCR <code>decoder</code> \"wordbeamsearch\" (accuracy)\"greedy\" (speed) Word beam search is more accurate but slower Accuracy vs. speed PaddleOCR <code>rec_batch_num</code> 1 (accuracy)8+ (speed) Larger batches process faster but use more memory Small text Both <code>min_confidence</code> 0.3 - 0.4 (default: 0.5) Lower confidence threshold to capture small/blurry text Text orientation PaddleOCR <code>use_angle_cls</code> <code>True</code> Enable angle classification for rotated text Asian languages PaddleOCR <code>lang</code> \"ch\", \"japan\", \"korea\" Use PaddleOCR for Asian languages"},{"location":"ocr/#next-steps","title":"Next Steps","text":"<p>With OCR capabilities, you can explore:</p> <ul> <li>Layout Analysis for automatically detecting document structure</li> <li>Document QA for asking questions about your documents</li> <li>Understanding PDF Fonts for font-related text extraction issues</li> <li>Visual Debugging for visualizing OCR results</li> </ul>"},{"location":"pdf-navigation/","title":"PDF Navigation","text":"<p>This guide covers the basics of working with PDFs in Natural PDF - opening documents, accessing pages, and navigating through content.</p>"},{"location":"pdf-navigation/#opening-a-pdf","title":"Opening a PDF","text":"<p>The main entry point to Natural PDF is the <code>PDF</code> class:</p> <pre><code>from natural_pdf import PDF\n\n# Open a PDF file\npdf = PDF('document.pdf')\n\n# Use a context manager to automatically close the file\nwith PDF('document.pdf') as pdf:\n    # Work with the PDF here\n    pass  # File closes automatically when the block exits\n\n# Customize with non-default options when needed\npdf = PDF(\n    'document.pdf',\n    keep_spaces=False,  # Don't preserve spaces in text elements\n    font_attrs=['fontname', 'size', 'color']  # Include color in font grouping\n)\n</code></pre>"},{"location":"pdf-navigation/#accessing-pages","title":"Accessing Pages","text":"<p>Once you have a PDF object, you can access its pages:</p> <pre><code># Get the total number of pages\nnum_pages = len(pdf)\nprint(f\"This PDF has {num_pages} pages\")\n\n# Get a specific page (0-indexed)\nfirst_page = pdf.pages[0]\nlast_page = pdf.pages[-1]\n\n# Iterate through all pages\nfor page in pdf.pages:\n    print(f\"Page {page.page_number} has dimensions {page.width} x {page.height}\")\n</code></pre>"},{"location":"pdf-navigation/#page-properties","title":"Page Properties","text":"<p>Each <code>Page</code> object has useful properties:</p> <pre><code># Page dimensions in points (1/72 inch)\nwidth = page.width\nheight = page.height\n\n# Page number (1-indexed as shown in PDF viewers)\npage_number = page.page_number\n\n# Page index (0-indexed position in the PDF)\npage_index = page.page_index\n</code></pre>"},{"location":"pdf-navigation/#pdf-configuration-options","title":"PDF Configuration Options","text":"<p>When opening a PDF, you can configure various behaviors:</p> <pre><code># Configure text handling\npdf = PDF(\n    'document.pdf',\n\n    # Reading order options\n    reading_order=True,  # Sort elements in reading order (default: True)\n\n    # Text preservation options\n    keep_spaces=True,    # Keep spaces in word elements (default: True)\n\n    # Font handling\n    font_attrs=['fontname', 'size', 'bold'],  # Group text by these font attributes\n\n    # OCR configuration\n    ocr={\n        \"enabled\": \"auto\",  # Automatically use OCR when needed\n        \"languages\": [\"en\"],  # Languages to use for OCR\n        \"min_confidence\": 0.5  # Confidence threshold for OCR\n    },\n\n    # OCR engine selection\n    ocr_engine=\"easyocr\"  # Use EasyOCR engine (default)\n)\n</code></pre>"},{"location":"pdf-navigation/#working-across-pages","title":"Working Across Pages","text":"<p>Natural PDF makes it easy to work with content across multiple pages:</p> <pre><code># Extract text from all pages\nall_text = pdf.extract_text()\n\n# Find elements across all pages\nall_headings = pdf.find_all('text[size&gt;=14]:bold')\n\n# Add exclusion zones to all pages (like headers/footers)\npdf.add_exclusion(\n    lambda page: page.find('text:contains(\"CONFIDENTIAL\")').above() if page.find('text:contains(\"CONFIDENTIAL\")') else None,\n    label=\"header\"\n)\n</code></pre>"},{"location":"pdf-navigation/#the-page-collection","title":"The Page Collection","text":"<p>The <code>pdf.pages</code> object is a <code>PageCollection</code> that allows batch operations on pages:</p> <pre><code># Get sections across all pages\nsections = pdf.pages.get_sections(\n    start_elements='text[size&gt;=14]:bold',\n    new_section_on_page_break=True  # Start a new section on page boundaries\n)\n\n# Extract text from specific pages\ntext = pdf.pages[2:5].extract_text()\n\n# Find elements across specific pages\nelements = pdf.pages[2:5].find_all('text:contains(\"Annual Report\")')\n</code></pre>"},{"location":"pdf-navigation/#working-with-multiple-pages","title":"Working with Multiple Pages","text":"<p>Here are some ways to handle content that spans across multiple pages:</p> <pre><code># Extract text from all pages with a consistent format\nall_text = pdf.extract_text()\n\n# Find all instances of a phrase across all pages\nall_occurrences = pdf.find_all('text:contains(\"Revenue\")')\nprint(f\"Found {len(all_occurrences)} occurrences across the document\")\n\n# Group by page number\nby_page = {}\nfor element in all_occurrences:\n    page_num = element.page.page_number\n    if page_num not in by_page:\n        by_page[page_num] = []\n    by_page[page_num].append(element)\n\n# Print occurrences by page\nfor page_num, elements in by_page.items():\n    print(f\"Page {page_num}: {len(elements)} occurrences\")\n</code></pre>"},{"location":"pdf-navigation/#document-sections-across-pages","title":"Document Sections Across Pages","text":"<p>You can extract sections that span across multiple pages:</p> <pre><code># Get sections with headings as section starts\nsections = pdf.pages.get_sections(\n    start_elements='text[size&gt;=14]:bold',\n    new_section_on_page_break=True  # Optional: Create new sections at page boundaries\n)\n\n# Process each section\nfor i, section in enumerate(sections):\n    print(f\"Section {i+1}:\")\n    if hasattr(section, 'start_element') and section.start_element:\n        print(f\"  Starts with: {section.start_element.text}\")\n    print(f\"  Content: {section.extract_text()[:50]}...\")\n    print(f\"  Spans pages: {section.page.page_number}\")\n</code></pre>"},{"location":"pdf-navigation/#using-ocr-across-pages","title":"Using OCR Across Pages","text":"<p>For scanned documents, you can apply OCR across multiple pages:</p> <pre><code># Enable OCR for the document\npdf = PDF('scanned_document.pdf', ocr=True)\n\n# Apply OCR to all pages\nfor page in pdf.pages:\n    page.apply_ocr()\n\n# Extract text from the entire document\nall_text = pdf.extract_text()\n\n# Find OCR text elements across all pages\nocr_elements = pdf.find_all('text[source=ocr]')\n</code></pre>"},{"location":"pdf-navigation/#complete-multi-page-navigation-example","title":"Complete Multi-page Navigation Example","text":"<p>Here's a complete example of working with a multi-page document:</p> <pre><code>from natural_pdf import PDF\n\n# Open a PDF\npdf = PDF('annual_report.pdf')\nprint(f\"Document has {len(pdf)} pages\")\n\n# Find all headings across the document\nheadings = pdf.find_all('text[size&gt;=14]:bold')\nprint(f\"Found {len(headings)} headings across all pages\")\n\n# Group headings by page\nheading_by_page = {}\nfor heading in headings:\n    page_num = heading.page.page_number\n    if page_num not in heading_by_page:\n        heading_by_page[page_num] = []\n    heading_by_page[page_num].append(heading)\n\n# Print headings by page\nfor page_num in sorted(heading_by_page.keys()):\n    print(f\"\\nPage {page_num} headings:\")\n    for heading in heading_by_page[page_num]:\n        print(f\"  - {heading.text}\")\n\n# Find the financial section across all pages\nfinancial_heading = pdf.find('text:contains(\"Financial\")')\nif financial_heading:\n    print(f\"\\nFound Financial section on page {financial_heading.page.page_number}\")\n\n    # Extract the financial section\n    financial_section = financial_heading.below()\n    financial_text = financial_section.extract_text()\n    print(f\"Financial section excerpt: {financial_text[:200]}...\")\n\n    # Look for the next heading in the document (might be on next page)\n    next_heading = None\n    for heading in headings:\n        if heading.page.page_number &gt; financial_heading.page.page_number or (\n            heading.page.page_number == financial_heading.page.page_number and \n            heading.top &gt; financial_heading.top\n        ):\n            next_heading = heading\n            break\n\n    if next_heading:\n        print(f\"Next section is '{next_heading.text}' on page {next_heading.page.page_number}\")\n\n# Extract text from a page range\npages_3_to_5_text = pdf.pages[2:5].extract_text()  # Pages 3-5 (0-indexed)\nprint(f\"\\nText from pages 3-5 (excerpt): {pages_3_to_5_text[:200]}...\")\n</code></pre>"},{"location":"pdf-navigation/#next-steps","title":"Next Steps","text":"<p>Now that you know how to navigate PDFs, you can:</p> <ul> <li>Find elements using selectors</li> <li>Extract text from your documents</li> <li>Work with specific regions</li> </ul>"},{"location":"regions/","title":"Working with Regions","text":"<p>Regions are one of the most powerful features in Natural PDF. A region is simply a rectangular area on a page that you can interact with - extract text from it, find elements within it, or generate images of it.</p> <p>You can create regions in several ways:</p> <ol> <li>Manual creation: <code>page.create_region(x0, y0, x1, y1)</code></li> <li>Spatial relations: <code>element.above()</code> or <code>element.below()</code></li> <li>Content-based: <code>element.select_until(\"another element\")</code></li> <li>Structural: <code>page.get_sections(start_elements=\"text:bold\")</code></li> </ol>"},{"location":"regions/#creating-regions","title":"Creating Regions","text":"<p>There are several ways to create regions:</p>"},{"location":"regions/#from-an-element","title":"From an Element","text":"<p>The simplest way to create a region is based on an existing element:</p> <pre><code># Get a region below a heading\ntitle = page.find('text:contains(\"Summary\")')\nsummary_region = title.below()\n\n# Get a region above an element\nfooter = page.find('text:contains(\"Page\")')\ncontent_region = footer.above()\n</code></pre>"},{"location":"regions/#from-one-element-to-another","title":"From One Element to Another","text":"<p>You can create a region spanning from one element to another:</p> <pre><code>start = page.find('text:contains(\"Introduction\")')\nend = page.find('text:contains(\"Conclusion\")')\n\n# Create a region from start to end\ncontent_region = start.until(end)\n</code></pre>"},{"location":"regions/#manually-by-coordinates","title":"Manually by Coordinates","text":"<p>You can create a region directly using coordinates:</p> <pre><code># Create a region from scratch\n# (x0, top, x1, bottom)\nregion = page.create_region(100, 200, 400, 500)\n</code></pre>"},{"location":"regions/#from-layout-analysis","title":"From Layout Analysis","text":"<p>You can get regions detected by document layout analysis:</p> <pre><code># Get regions detected by layout analysis\npage.analyze_layout()\nlayout_regions = page.find_all('region')\n\n# Get a specific type of region\ntables = page.find_all('region[type=table]')\n</code></pre>"},{"location":"regions/#working-with-regions_1","title":"Working with Regions","text":"<p>Once you have a region, you can:</p>"},{"location":"regions/#extract-text","title":"Extract Text","text":"<pre><code># Extract all text from the region\ntext = region.extract_text()\n</code></pre>"},{"location":"regions/#find-elements-within-the-region","title":"Find Elements Within the Region","text":"<pre><code># Find elements within the region\nbold_text = region.find_all('text:bold')\n</code></pre>"},{"location":"regions/#generate-an-image-of-the-region","title":"Generate an Image of the Region","text":"<pre><code># Generate an image of just this region\nregion_image = region.to_image(resolution=150)\n\n# Save it to a file\nregion.save_image(\"region.png\")\n\n# Options for customization\nregion.save_image(\n    \"region_no_border.png\", \n    crop_only=True           # Don't add a border\n)\n\nregion.save_image(\n    \"region_high_res.png\", \n    resolution=300           # Higher resolution\n)\n</code></pre>"},{"location":"regions/#modify-the-region","title":"Modify the Region","text":"<p>You can expand or adjust a region:</p> <pre><code># Expand a region in all directions\nlarger_region = region.expand(left=10, right=10, top=10, bottom=10)\n\n# Expand by a factor\ndoubled_region = region.expand(width_factor=2, height_factor=2)\n</code></pre>"},{"location":"regions/#practical-examples","title":"Practical Examples","text":"<p>Here are some practical examples of using regions:</p>"},{"location":"regions/#extract-a-section-between-headings","title":"Extract a Section Between Headings","text":"<pre><code>heading1 = page.find('text:contains(\"Introduction\")')\nheading2 = page.find('text:contains(\"Methods\")')\n\n# Get the content between the headings\ncontent = heading1.below(until='text:contains(\"Methods\")', include_endpoint=False)\ntext = content.extract_text()\n</code></pre>"},{"location":"regions/#extract-a-table-with-its-caption","title":"Extract a Table with its Caption","text":"<pre><code># Find a table caption\ncaption = page.find('text:contains(\"Table 1\")')\n\n# Look for the table below the caption\ntable_region = caption.below(height=200)  # Approximate height\n\n# Extract the table\ntable_text = table_region.extract_text()\n</code></pre>"},{"location":"regions/#exclude-headers-and-footers","title":"Exclude Headers and Footers","text":"<pre><code># Define header and footer as exclusion zones\nheader = page.find('text:contains(\"CONFIDENTIAL\")').above()\nfooter = page.find('text:contains(\"Page\")').below()\n\npage.add_exclusion(header)\npage.add_exclusion(footer)\n\n# Now extract text from a region without the header/footer content\nregion = page.create_region(50, 100, page.width - 50, page.height - 100)\nclean_text = region.extract_text()  # Headers/footers automatically excluded\n</code></pre>"},{"location":"regions/#next-steps","title":"Next Steps","text":"<p>Now that you know how to work with regions, check out:</p> <ul> <li>Visual Debugging to see what you're extracting</li> <li>OCR for working with scanned documents</li> <li>Layout Analysis for automatically detecting regions</li> </ul>"},{"location":"tables/","title":"Table Extraction","text":"<p>PDFs with tables can be challenging to work with, but Natural PDF provides tools to make table extraction easier and more accurate.</p>"},{"location":"tables/#basic-table-extraction","title":"Basic Table Extraction","text":"<p>The simplest way to extract a table is with the <code>extract_table()</code> method:</p> <pre><code>from natural_pdf import PDF\n\npdf = PDF('document.pdf')\npage = pdf.pages[0]\n\n# Extract the first table found on the page\ntable = page.extract_table()\nif table:\n    for row in table:\n        print(row)\n</code></pre>"},{"location":"tables/#working-with-detected-tables","title":"Working with Detected Tables","text":"<p>For better results, you can use layout analysis to find tables first:</p> <pre><code># Detect tables using layout analysis\npage.analyze_layout()  # Uses YOLO model by default\ntables = page.find_all('region[type=table]')\n\nif tables:\n    print(f\"Found {len(tables)} tables\")\n\n    # Extract the first table\n    first_table = tables[0]\n\n    # Highlight the table\n    first_table.highlight(color=(0, 0, 1, 0.2), label=\"Table\")\n    page.save_image(\"detected_table.png\")\n\n    # Extract the table data\n    table_data = first_table.extract_table()  # Uses pdfplumber by default\n\n    # Print the table data\n    for row in table_data:\n        print(row)\n</code></pre>"},{"location":"tables/#table-detection-models","title":"Table Detection Models","text":"<p>Natural PDF offers two different approaches to table detection:</p> <ol> <li> <p>YOLO: The default model detects tables as single regions, identifying their boundaries on the page. This makes it easier for pdfplumber to extract the table data from the correct region, but doesn't provide information about the internal table structure.</p> </li> <li> <p>TATR (Table Transformer): A specialized table detection model that not only identifies tables but also analyzes their internal structure (rows, columns, headers). This is particularly useful for complex tables where pdfplumber might struggle.</p> </li> </ol> <pre><code># Simple table detection with YOLO\npage.analyze_layout()  # Uses YOLO by default\ntables = page.find_all('region[type=table]')\n\n# Comprehensive table structure detection with TATR\npage.analyze_layout(model=\"tatr\") \ntables = page.find_all('region[type=table]')\nrows = page.find_all('region[type=table-row]')\ncolumns = page.find_all('region[type=table-column]')\nheaders = page.find_all('region[type=table-column-header]')\n</code></pre> <p>When you detect tables with TATR, the library can automatically generate cell regions at the intersections of rows and columns, providing more accurate extraction compared to pdfplumber's algorithm.</p>"},{"location":"tables/#controlling-table-extraction-method","title":"Controlling Table Extraction Method","text":"<p>Natural PDF automatically selects the appropriate extraction method based on the detection model used, but you can also explicitly specify which method to use:</p> <pre><code># Basic approach - use pdfplumber's table extraction\ntable_plumber = page.extract_table(method='plumber')\n\n# Advanced approach for complex tables \npage.analyze_layout(model=\"tatr\")  # Detect detailed table structure\ntable_region = page.find('region[type=table]')\nif table_region:\n    # The TATR method uses detected rows and columns to create cells\n    # This often handles complex tables better than pdfplumber\n    table_tatr = table_region.extract_table(method='tatr')\n</code></pre> <p>When to use each approach:</p> <ul> <li>pdfplumber method: Works well for simple tables with clear borders or good spacing</li> <li>TATR method: Better for complex tables, especially when:</li> <li>Borders are missing or inconsistent</li> <li>Cells span multiple rows or columns</li> <li>Tables have irregular structures</li> <li>Text alignment is complex</li> </ul> <p>If you run <code>analyze_layout(model=\"tatr\")</code> and then call <code>extract_table()</code> on a table region without specifying a method, Natural PDF will automatically use the TATR method since it has the detailed structure information available.</p>"},{"location":"tables/#table-settings","title":"Table Settings","text":"<p>You can customize table extraction settings:</p> <pre><code># With pdfplumber method\ntable_settings = {\n    \"vertical_strategy\": \"text\",\n    \"horizontal_strategy\": \"lines\",\n    \"intersection_x_tolerance\": 10,\n    \"intersection_y_tolerance\": 10\n}\n\ntable = page.extract_table(table_settings=table_settings)\n</code></pre>"},{"location":"tables/#saving-tables","title":"Saving Tables","text":"<p>You can save extracted tables to files:</p> <pre><code>import csv\n\n# Extract a table\ntable = page.extract_table()\n\n# Save as CSV\nif table:\n    with open(\"table.csv\", \"w\", newline=\"\") as f:\n        writer = csv.writer(f)\n        writer.writerows(table)\n\n# Save as JSON\nimport json\nif table:\n    # Convert to a list of dictionaries (assuming first row is header)\n    header = table[0]\n    data = []\n    for row in table[1:]:\n        row_dict = {header[i]: cell for i, cell in enumerate(row)}\n        data.append(row_dict)\n\n    with open(\"table.json\", \"w\") as f:\n        json.dump(data, f, indent=2)\n</code></pre>"},{"location":"tables/#working-with-table-structure","title":"Working with Table Structure","text":"<p>For precise table extraction, the TATR model provides detailed structural analysis:</p> <pre><code># Analyze table structure using TATR model\npage.analyze_layout(model=\"tatr\")\n\n# Get table structure elements\ntable = page.find('region[type=table]')\nrows = page.find_all('region[type=table-row]')\ncolumns = page.find_all('region[type=table-column]')\nheaders = page.find_all('region[type=table-column-header]')\n\nif table:\n    # TATR automatically creates cells at row/column intersections\n    cells = table.create_cells()\n    print(f\"Found {len(cells)} cells in the table\")\n\n    # Extract data from individual cells\n    for cell in cells:\n        print(f\"Cell at {cell.x0},{cell.top} to {cell.x1},{cell.bottom}: {cell.extract_text().strip()}\")\n\n    # Or extract the entire table directly\n    table_data = table.extract_table(method='tatr')\n    for row in table_data:\n        print(row)\n</code></pre>"},{"location":"tables/#yolo-vs-tatr-for-table-extraction","title":"YOLO vs TATR for Table Extraction","text":"<p>Here's a comparison of the two approaches:</p> Feature YOLO + pdfplumber TATR Detection speed Faster Slower but more thorough Simple tables Good results Good results Complex tables May struggle Usually better Cell detection Uses line detection algorithm Uses machine learning to identify rows/columns Structure awareness None Detects rows, columns, headers Memory usage Lower Higher Best use case Simple tables with clear lines Complex tables with irregular structure <p>When dealing with a document containing many tables, a good strategy is:</p> <ol> <li>Start with YOLO detection to identify all tables</li> <li>For any tables that aren't extracted correctly, use TATR for those specific tables</li> <li>For very complex tables, use TATR with manual cell creation</li> </ol> <p>For more manual control, you can build a structured table from detected elements:</p> <pre><code># Get header texts\nheader_texts = []\nif headers:\n    for header in headers:\n        header_texts.append(header.extract_text().strip())\n\n# Process each row\nstructured_table = []\nfor row in rows:\n    row_data = {}\n    for i, col in enumerate(columns):\n        # Create a cell at the intersection of row and column\n        cell_region = page.create_region(\n            col.x0, row.top, col.x1, row.bottom\n        )\n\n        # Extract cell text\n        cell_text = cell_region.extract_text().strip()\n\n        # Add to row data\n        if i &lt; len(header_texts):\n            row_data[header_texts[i]] = cell_text\n        else:\n            row_data[f\"Column {i+1}\"] = cell_text\n\n    structured_table.append(row_data)\n\n# Print structured table\nimport json\nprint(json.dumps(structured_table, indent=2))\n</code></pre>"},{"location":"tables/#ocr-for-tables","title":"OCR for Tables","text":"<p>For scanned documents or images with tables:</p> <pre><code># Enable OCR\npdf = PDF('scanned_document.pdf', ocr=True)\npage = pdf.pages[0]\n\n# Apply OCR first\npage.apply_ocr()\n\n# Then detect and extract tables\npage.analyze_layout(model=\"tatr\")\ntables = page.find_all('region[type=table]')\n\nif tables:\n    # Extract table with OCR text\n    table_data = tables[0].extract_table(use_ocr=True)\n\n    # Print the table\n    for row in table_data:\n        print(row)\n</code></pre>"},{"location":"tables/#visualizing-tables","title":"Visualizing Tables","text":"<p>You can visualize detected tables:</p> <pre><code># Detect tables\npage.analyze_layout()\ntables = page.find_all('region[type=table]')\n\n# Highlight tables\ntables.highlight(color=(0, 0, 1, 0.2), label=\"Tables\")\n\n# With table structure detection\npage.analyze_layout(model=\"tatr\")\ntables = page.find_all('region[type=table]')\nrows = page.find_all('region[type=table-row]')\ncolumns = page.find_all('region[type=table-column]')\nheaders = page.find_all('region[type=table-column-header]')\n\n# Color-code table elements\ntables.highlight(color=(0, 0, 1, 0.2), label=\"Tables\")\nrows.highlight(color=(1, 0, 0, 0.2), label=\"Rows\")\ncolumns.highlight(color=(0, 1, 0, 0.2), label=\"Columns\")\nheaders.highlight(color=(0.5, 0, 0.5, 0.2), label=\"Headers\")\n\n# Save the visualization\npage.save_image(\"table_structure.png\", labels=True)\n</code></pre>"},{"location":"tables/#creating-table-images","title":"Creating Table Images","text":"<p>You can create images of just the tables:</p> <pre><code># Find a table\ntable = page.find('region[type=table]')\nif table:\n    # Generate an image of just the table\n    table_image = table.to_image(resolution=300)\n    table.save_image(\"table.png\")\n</code></pre>"},{"location":"tables/#a-complete-table-extraction-example","title":"A Complete Table Extraction Example","text":"<p>Here's a complete example that demonstrates table extraction using the TATR model:</p> <pre><code>from natural_pdf import PDF\nimport csv\n\n# Open a PDF with tables\npdf = PDF(\"document_with_tables.pdf\")\npage = pdf.pages[0]  # Assuming table is on the first page\n\n# Detect tables using Table Transformer\npage.analyze_layout(model=\"tatr\", confidence=0.4)\n\n# Find table regions\ntables = page.find_all('region[type=table]')\nif not tables:\n    print(\"No tables found.\")\n    exit()\n\nprint(f\"Found {len(tables)} tables\")\n\n# Process the first table\ntable = tables[0]\n\n# Highlight the table and its structure\ntable.highlight(color=(0, 0, 1, 0.2), label=\"Table\")\npage.find_all('region[type=table-row]').highlight(color=(1, 0, 0, 0.2), label=\"Rows\")\npage.find_all('region[type=table-column]').highlight(color=(0, 1, 0, 0.2), label=\"Columns\")\npage.find_all('region[type=table-column-header]').highlight(color=(0.5, 0, 0.5, 0.2), label=\"Headers\")\n\n# Save visualization\npage.save_image(\"table_structure_detail.png\", labels=True)\n\n# Extract the table data using TATR\ntable_data = table.extract_table(method='tatr')\n\n# Print the extracted data\nfor row in table_data:\n    print(row)\n\n# Save to CSV\nwith open(\"table_with_tatr.csv\", \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerows(table_data)\n\nprint(f\"Table extracted and saved to table_with_tatr.csv\")\n</code></pre>"},{"location":"tables/#coming-soon-tables-across-pages","title":"Coming Soon: Tables Across Pages","text":"<p>Support for extracting tables that span across multiple pages is under development and will be available in a future release.</p>"},{"location":"tables/#next-steps","title":"Next Steps","text":"<p>Now that you know how to work with tables, you might want to explore:</p> <ul> <li>Layout Analysis for detecting document structure including tables</li> <li>Table Structure Detection for detailed TATR table analysis</li> <li>Document QA for asking questions about your tables</li> <li>Visual Debugging for visualizing extraction results</li> <li>PDF Extraction Challenges for handling difficult tables</li> </ul>"},{"location":"text-extraction/","title":"Text Extraction","text":"<p>Extracting text from PDFs is one of the most common tasks with Natural PDF. This section covers different approaches to text extraction, from basic to advanced.</p>"},{"location":"text-extraction/#basic-text-extraction","title":"Basic Text Extraction","text":"<p>The simplest way to extract text is to use the <code>extract_text()</code> method:</p> <pre><code>from natural_pdf import PDF\n\npdf = PDF('document.pdf')\npage = pdf.pages[0]\n\n# Extract all text from a page\ntext = page.extract_text()\nprint(text)\n\n# Extract text from the entire document\nall_text = pdf.extract_text()\n</code></pre>"},{"location":"text-extraction/#extracting-text-from-specific-elements","title":"Extracting Text from Specific Elements","text":"<p>You can extract text from specific elements:</p> <pre><code># Find a specific element\ntitle = page.find('text:contains(\"Summary\")')\nif title:\n    # Get just that element's text\n    title_text = title.text\n    print(f\"Title: {title_text}\")\n\n# Find multiple elements and extract their text\nheadings = page.find_all('text[size&gt;=14]:bold')\nheadings_text = headings.extract_text()\n</code></pre>"},{"location":"text-extraction/#multi-word-searches","title":"Multi-Word Searches","text":"<p>Natural PDF has enhanced support for multi-word searches:</p> <pre><code># Search for elements containing full phrases\nannual_report = page.find('text:contains(\"Annual Report\")')\n\n# Case-insensitive search\nfinancial_statement = page.find('text:contains(\"financial statement\")', case=False)\n\n# Regular expression search\nyear_report = page.find('text:contains(\"\\\\d{4}\\\\s+Report\")', regex=True)\n\n# Combining options\nsummary = page.find('text:contains(\"executive summary\")', regex=True, case=False)\n</code></pre> <p>The multi-word search feature works because Natural PDF preserves spaces in text elements by default. You can control this behavior:</p> <pre><code># Keep spaces (default behavior)\npdf = PDF('document.pdf', keep_spaces=True)\n\n# Legacy behavior (break at spaces)\npdf = PDF('document.pdf', keep_spaces=False)\n</code></pre>"},{"location":"text-extraction/#extracting-text-from-regions","title":"Extracting Text from Regions","text":"<p>You can extract text from specific regions of a page:</p> <pre><code># Create a region and extract text from it\ntitle = page.find('text:contains(\"Introduction\")')\ncontent = title.below()\nintro_text = content.extract_text()\n\n# Extract text from a region between elements\nstart = page.find('text:contains(\"Method\")')\nend = page.find('text:contains(\"Results\")')\nmethod_section = start.below(until='text:contains(\"Results\")', include_until=False)\nmethod_text = method_section.extract_text()\n\n# Create a region manually\nregion = page.create_region(100, 200, 500, 600)  # x0, top, x1, bottom\nregion_text = region.extract_text()\n</code></pre>"},{"location":"text-extraction/#filtering-out-headers-and-footers","title":"Filtering Out Headers and Footers","text":"<p>A common challenge with PDF extraction is filtering out headers and footers. Natural PDF makes this easy with exclusion zones:</p> <pre><code># Define header and footer as exclusion zones\nheader = page.find('text:contains(\"Confidential\")').above()\npage.add_exclusion(header)\n\nfooter = page.find('text:contains(\"Page\")').below()\npage.add_exclusion(footer)\n\n# Now extract text without headers and footers\nclean_text = page.extract_text()  # Exclusions are applied by default\n\n# You can also disable exclusions if needed\nfull_text = page.extract_text(apply_exclusions=False)\n\n# Add exclusions at the PDF level that apply to all pages\npdf.add_exclusion(\n    lambda page: page.find('text:contains(\"Confidential\")').above(),\n    label=\"header\"\n)\npdf.add_exclusion(\n    lambda page: page.find_all('line')[-1].below(),\n    label=\"footer\"\n)\n\n# Now extract text from the entire document without headers/footers\nclean_text = pdf.extract_text()\n</code></pre>"},{"location":"text-extraction/#optimized-exclusion-handling","title":"Optimized Exclusion Handling","text":"<p>Natural PDF uses smart region exclusion handling for better performance:</p> <pre><code># Create a region that intersects with header exclusion\nheader_excl = page.add_exclusion(page.find('text:contains(\"HEADER\")').above())\nmiddle_region = page.create_region(50, page.height * 0.25, page.width - 50, page.height * 0.75)\n\n# Extract text - will automatically use efficient cropping for header exclusion\nmiddle_text = middle_region.extract_text()\n</code></pre> <p>The system automatically chooses the best exclusion strategy: - No intersection with exclusions: exclusions are ignored entirely - Header/footer exclusions: uses efficient cropping approach - Complex exclusions: uses element filtering with a warning</p>"},{"location":"text-extraction/#controlling-whitespace","title":"Controlling Whitespace","text":"<p>You can control how whitespace is handled during extraction:</p> <pre><code># Keep blank characters (default)\ntext = page.extract_text(keep_blank_chars=True)\n\n# Remove blank characters\ntext = page.extract_text(keep_blank_chars=False)\n\n# Extract with original whitespace preserved\ntext = page.extract_text(preserve_whitespace=True)  # Alias for keep_blank_chars\n</code></pre>"},{"location":"text-extraction/#font-aware-text-extraction","title":"Font-Aware Text Extraction","text":"<p>Natural PDF groups characters into words based on font attributes to preserve formatting:</p> <pre><code># Default: Group by font name and size\npdf = PDF(\"document.pdf\")  # Default: font_attrs=['fontname', 'size']\n\n# Spatial only: Group only by position\npdf = PDF(\"document.pdf\", font_attrs=[])\n\n# Custom: Group by font name, size, and color\npdf = PDF(\"document.pdf\", font_attrs=['fontname', 'size', 'non_stroking_color'])\n</code></pre> <p>This helps preserve text formatting during extraction: changes in font attributes break words, so different styles remain separate.</p>"},{"location":"text-extraction/#font-information-access","title":"Font Information Access","text":"<p>You can access detailed font information for any text element:</p> <pre><code>element = page.find('text')\nprint(element)  # Shows font name, size, style, etc.\nprint(element.font_info())  # Shows all available font properties\n\n# Check text style properties\nif element.bold:\n    print(\"This is bold text\")\nif element.italic:\n    print(\"This is italic text\")\n\n# Get font name and size\nfont_name = element.fontname\nfont_size = element.size\n\n# Find elements with specific font attributes\narial_text = page.find_all('text[fontname*=Arial]')\nbig_text = page.find_all('text[size&gt;=14]')\n</code></pre>"},{"location":"text-extraction/#working-with-font-styles","title":"Working with Font Styles","text":"<p>Natural PDF can group text by font style, which helps with identifying headings, body text, etc.:</p> <pre><code># Analyze text styles on the page\ntext_styles = page.analyze_text_styles()\n\n# Extract text from a specific style\nif \"Text Style 1\" in text_styles:\n    heading_style = text_styles[\"Text Style 1\"]\n    headings_text = heading_style.extract_text()\n\n# Visualize the text styles\npage.highlight_text_styles()\npage.save_image(\"text_styles.png\")\n\n# Combine with highlight_all\npage.highlight_all(include_text_styles=True)\n</code></pre>"},{"location":"text-extraction/#working-with-font-variants","title":"Working with Font Variants","text":"<p>Some PDFs use font variants (with prefixes like 'AAAAAB+') to distinguish visually different text:</p> <pre><code># Find text with a specific font variant\nvariant_text = page.find_all('text[font-variant=\"AAAAAB\"]')\n\n# Filter by both font variant and other attributes\nbold_variant = page.find_all('text[font-variant=\"AAAAAB\"][size&gt;=10]:bold')\n</code></pre>"},{"location":"text-extraction/#reading-order","title":"Reading Order","text":"<p>Text extraction respects the natural reading order of the document (top-to-bottom, left-to-right by default):</p> <pre><code># Extract with default reading order\ntext = page.extract_text()\n\n# Get elements in reading order to process manually\nelements = page.find_all('text')  # Already sorted in reading order\nfor element in elements:\n    print(element.text)\n</code></pre>"},{"location":"text-extraction/#element-navigation","title":"Element Navigation","text":"<p>You can navigate between elements in reading order:</p> <pre><code># Find the next element in reading order\nelement = page.find('text:contains(\"Introduction\")')\nnext_element = element.next()  # Next element regardless of type\nnext_text = element.next('text')  # Next text element\nnext_bold = element.next('text:bold', limit=20)  # Next bold text within 20 elements\n\n# Find the previous element in reading order\nprev_element = element.prev()  # Previous element regardless of type\nprev_heading = element.prev('text[size&gt;=12]')  # Previous large text\n\n# Find the nearest element by Euclidean distance\nnearest_element = element.nearest('rect')  # Nearest rectangle\nnearest_with_limit = element.nearest('text:contains(\"Table\")', max_distance=100)  # Within 100 points\n</code></pre>"},{"location":"text-extraction/#working-with-ocr-text","title":"Working with OCR Text","text":"<p>For scanned documents, you can extract text using OCR:</p> <pre><code># Enable OCR when opening the PDF\npdf = PDF('scanned_document.pdf', ocr=True)\n\n# Extract text with OCR\ntext = page.extract_text()  # OCR applied automatically\n\n# Force OCR even if text is present\nocr_text = page.extract_text(ocr=True)\n\n# Find and extract only OCR text\nocr_elements = page.find_all('text[source=ocr]')\nocr_only_text = ocr_elements.extract_text()\n\n# Filter OCR elements by confidence\nhigh_confidence = page.find_all('text[source=ocr][confidence&gt;=0.8]')\n</code></pre>"},{"location":"text-extraction/#complete-text-extraction-example","title":"Complete Text Extraction Example","text":"<p>Here's a complete example that demonstrates various text extraction techniques:</p> <pre><code>from natural_pdf import PDF\nimport re\n\n# Open a PDF with text extraction options\npdf = PDF(\n    \"document.pdf\",\n    keep_spaces=True,  # Enable multi-word searches\n    font_attrs=[\"fontname\", \"size\", \"bold\", \"italic\"]  # Font-aware text extraction\n)\n\n# Add document-wide exclusions for headers and footers\npdf.add_exclusion(\n    lambda page: page.find('text:contains(\"Page\")').below() if page.find('text:contains(\"Page\")') else None,\n    label=\"footers\"\n)\n\n# Process the first page\npage = pdf.pages[0]\n\n# Analyze text styles\nstyles = page.analyze_text_styles()\nprint(f\"Found {len(styles)} distinct text styles\")\n\n# Extract headings (largest text style)\nlargest_style = None\nlargest_size = 0\nfor style_name, elements in styles.items():\n    if elements and hasattr(elements[0], 'size'):\n        if elements[0].size &gt; largest_size:\n            largest_size = elements[0].size\n            largest_style = elements\n\nif largest_style:\n    headings = largest_style\n    print(\"Headings:\")\n    for heading in headings:\n        print(f\"  - {heading.text}\")\n\n    # Process sections under each heading\n    for heading in headings:\n        # Find the next heading or end of page\n        next_heading = heading.next('text[size&gt;={size}]'.format(size=largest_size-1))\n        if next_heading:\n            section = heading.below(until=next_heading, include_until=False)\n        else:\n            section = heading.below()\n\n        print(f\"\\nSection: {heading.text}\")\n        section_text = section.extract_text()\n        print(section_text[:200] + \"...\" if len(section_text) &gt; 200 else section_text)\n\n        # Find specific information with regex\n        if \"financial\" in heading.text.lower():\n            # Look for currency amounts\n            amounts = re.findall(r'\\$\\d+(?:,\\d+)*(?:\\.\\d+)?', section_text)\n            if amounts:\n                print(\"Found amounts:\", amounts)\n\n# Extract all text without headers/footers\nprint(\"\\nFull document text (without headers/footers):\")\nall_text = pdf.extract_text()\nprint(all_text[:500] + \"...\" if len(all_text) &gt; 500 else all_text)\n</code></pre>"},{"location":"text-extraction/#excluding-headers-and-footers","title":"Excluding Headers and Footers","text":"<p>You can exclude specific regions of the page (like headers and footers) from text extraction:</p> <pre><code>graph TD\n    subgraph \"PDF Content Extraction\"\n        subgraph \"Original PDF Page\"\n            header1[Header Text]\n            content1[Main Content]\n            footer1[Footer Text]\n\n            header1 --- content1\n            content1 --- footer1\n        end\n\n        subgraph \"After Applying Exclusions\"\n            header2[Excluded Header]\n            content2[Extracted Content]\n            footer2[Excluded Footer]\n\n            header2 -.- content2\n            content2 -.- footer2\n        end\n    end\n\n    style header1 fill:#ffcccc,stroke:#333\n    style footer1 fill:#ffcccc,stroke:#333\n    style content1 fill:#ccffcc,stroke:#333\n\n    style header2 fill:#ffcccc,stroke:#333,stroke-dasharray: 5 5\n    style footer2 fill:#ffcccc,stroke:#333,stroke-dasharray: 5 5\n    style content2 fill:#ccffcc,stroke:#333</code></pre> <pre><code># Add exclusion zones\n# Exclude header (top of page)\nheader = page.find('text:contains(\"Report Title\")')\nif header:\n    page.add_exclusion(header.above())\n\n# Exclude footer (bottom of page)\nfooter = page.find('text:contains(\"Page\")')\nif footer:\n    page.add_exclusion(footer.below())\n\n# Extract text without headers/footers\ntext = page.extract_text()  # Exclusions applied by default\ntext = page.extract_text(apply_exclusions=False)  # Ignore exclusions\n\n# PDF-level exclusion with lambdas (applies to all pages)\npdf.add_exclusion(\n    lambda page: page.find('text:contains(\"Header\")').above() if page.find('text:contains(\"Header\")') else None,\n    label=\"headers\"\n)\n\npdf.add_exclusion(\n    lambda page: page.find_all('line')[-1].below() if page.find_all('line') else None,\n    label=\"footers\"\n)\n\n# Extract text with exclusions\ntext = pdf.extract_text()\n</code></pre>"},{"location":"text-extraction/#next-steps","title":"Next Steps","text":"<p>Now that you know how to extract text, you might want to explore:</p> <ul> <li>Working with regions for more precise extraction</li> <li>OCR capabilities for scanned documents</li> <li>Document layout analysis for automatic structure detection</li> <li>Document QA for asking questions directly to your documents</li> </ul>"},{"location":"visual-debugging/","title":"Visual Debugging","text":"<p>Sometimes it's hard to understand what's happening when working with PDFs. Natural PDF provides powerful visual debugging tools to help you see what you're extracting.</p>"},{"location":"visual-debugging/#basic-highlighting","title":"Basic Highlighting","text":"<p>The simplest way to highlight elements is with the <code>highlight()</code> method:</p> <pre><code>from natural_pdf import PDF\n\npdf = PDF('document.pdf')\npage = pdf.pages[0]\n\n# Find a specific element and highlight it\ntitle = page.find('text:contains(\"Summary\")')\ntitle.highlight()\n\n# Show or save the highlighted page\npage.show()  # Returns a PIL Image that displays in notebooks\npage.save_image(\"highlighted.png\")\n</code></pre>"},{"location":"visual-debugging/#customizing-highlights","title":"Customizing Highlights","text":"<p>You can customize your highlights with colors and labels:</p> <pre><code># Highlight with a specific color (RGBA tuple)\ntitle.highlight(color=(1, 0, 0, 0.3))  # Red with 30% opacity\n\n# Add a label to the highlight\ntitle.highlight(label=\"Title\")\n\n# Combine color and label\ntable = page.find('rect[width&gt;=400][height&gt;=200]')\ntable.highlight(color=(0, 0, 1, 0.2), label=\"Table\")\n\n# Save with a legend that shows the labels\npage.save_image(\"highlighted_with_legend.png\", labels=True)\n</code></pre>"},{"location":"visual-debugging/#highlighting-multiple-elements","title":"Highlighting Multiple Elements","text":"<p>You can highlight multiple elements at once:</p> <pre><code># Find and highlight all headings\nheadings = page.find_all('text[size&gt;=14]:bold')\nheadings.highlight(color=(0, 0.5, 0, 0.3), label=\"Headings\")\n\n# Find and highlight all tables\ntables = page.find_all('region[type=table]')\ntables.highlight(color=(0, 0, 1, 0.2), label=\"Tables\")\n\n# Save the image with all highlights\npage.save_image(\"multiple_highlights.png\", labels=True)\n</code></pre>"},{"location":"visual-debugging/#highlight-all-elements","title":"Highlight All Elements","text":"<p>The <code>highlight_all()</code> method is great for quickly seeing all elements on a page:</p> <pre><code># Highlight all elements on the page\npage.highlight_all()\n\n# Save the image\npage.save_image(\"all_elements.png\", labels=True)\n\n# Highlight only specific types of elements\npage.highlight_all(include_types=['text', 'line'])\n\n# Include text styles in the highlighting\npage.highlight_all(include_text_styles=True)\n\n# Include layout regions in the highlighting\npage.highlight_all(include_layout_regions=True)\n</code></pre>"},{"location":"visual-debugging/#highlighting-regions","title":"Highlighting Regions","text":"<p>You can highlight regions to see what area you're working with:</p> <pre><code># Find a title and create a region below it\ntitle = page.find('text:contains(\"Introduction\")')\ncontent = title.below(height=200)\n\n# Highlight the region\ncontent.highlight(color=(0, 0.7, 0, 0.2), label=\"Introduction\")\n\n# Highlight region boundaries\ncontent.highlight(label=\"Region Boundary\")\n\n# Extract a cropped image of just this region\nregion_image = content.to_image(resolution=150)\ncontent.save_image(\"region.png\")\n</code></pre>"},{"location":"visual-debugging/#working-with-text-styles","title":"Working with Text Styles","text":"<p>Visualize text styles to understand the document structure:</p> <pre><code># Analyze and highlight text styles\nstyles = page.analyze_text_styles()\npage.highlight_text_styles()\npage.save_image(\"text_styles.png\", labels=True)\n\n# Work with a specific style\nif \"Text Style 1\" in styles:\n    title_style = styles[\"Text Style 1\"]\n    title_style.highlight(color=(1, 0, 0, 0.3), label=\"Title Style\")\n</code></pre>"},{"location":"visual-debugging/#displaying-attributes","title":"Displaying Attributes","text":"<p>You can display element attributes directly on the highlights:</p> <pre><code># Show confidence scores for OCR text\nocr_text = page.find_all('text[source=ocr]')\nocr_text.highlight(include_attrs=['confidence'])\n\n# Show region types and confidence for layout analysis\nregions = page.find_all('region')\nregions.highlight(include_attrs=['region_type', 'confidence'])\n\n# Show font information for text\ntext = page.find_all('text[size&gt;=12]')\ntext.highlight(include_attrs=['fontname', 'size'])\n</code></pre>"},{"location":"visual-debugging/#clearing-highlights","title":"Clearing Highlights","text":"<p>You can clear highlights when needed:</p> <pre><code># Clear all highlights\npage.clear_highlights()\n\n# Apply new highlights\npage.find_all('text:bold').highlight(label=\"Bold Text\")\n</code></pre>"},{"location":"visual-debugging/#composite-highlighting","title":"Composite Highlighting","text":"<p>You can build up complex visualizations layer by layer:</p> <pre><code># Clear any existing highlights\npage.clear_highlights()\n\n# Highlight different elements with different colors\npage.find_all('text:bold').highlight(color=(1, 0, 0, 0.3), label=\"Bold Text\")\npage.find_all('text:contains(\"Table\")').highlight(color=(0, 0, 1, 0.3), label=\"Table References\")\npage.find_all('line').highlight(color=(0, 0.5, 0, 0.3), label=\"Lines\")\n\n# Highlight regions\ntitle = page.find('text:contains(\"Summary\")')\nif title:\n    title.below(height=200).highlight(color=(0.5, 0, 0.5, 0.1), label=\"Summary Section\")\n\n# Save the composite image\npage.save_image(\"composite_highlight.png\", labels=True)\n</code></pre>"},{"location":"visual-debugging/#ocr-visualization","title":"OCR Visualization","text":"<p>Visualize OCR results with confidence levels:</p> <pre><code># Enable OCR\npdf = PDF('scanned_document.pdf', ocr=True)\npage = pdf.pages[0]\n\n# Apply OCR\nocr_elements = page.apply_ocr()\n\n# Highlight OCR elements by confidence level\nhigh_conf = page.find_all('text[source=ocr][confidence&gt;=0.8]')\nmed_conf = page.find_all('text[source=ocr][confidence&gt;=0.5][confidence&lt;0.8]')\nlow_conf = page.find_all('text[source=ocr][confidence&lt;0.5]')\n\nhigh_conf.highlight(color=(0, 1, 0, 0.3), label=\"High Confidence\")\nmed_conf.highlight(color=(1, 1, 0, 0.3), label=\"Medium Confidence\")\nlow_conf.highlight(color=(1, 0, 0, 0.3), label=\"Low Confidence\")\n\n# Save the visualization\npage.save_image(\"ocr_confidence.png\", labels=True)\n</code></pre>"},{"location":"visual-debugging/#document-qa-visualization","title":"Document QA Visualization","text":"<p>Visualize document QA results:</p> <pre><code># Ask a question to the document\nresult = page.ask(\"What is the total revenue?\")\n\nif result.get(\"found\", False):\n    # Highlight the answer source elements\n    if \"source_elements\" in result:\n        for element in result[\"source_elements\"]:\n            element.highlight(color=(1, 0.5, 0, 0.3), label=\"Answer\")\n\n    # Add the question and answer as an annotation\n    question = \"What is the total revenue?\"\n    answer = result[\"answer\"]\n    confidence = result[\"confidence\"]\n\n    # Save the highlighted image\n    page.save_image(\"qa_visualization.png\", labels=True)\n</code></pre>"},{"location":"visual-debugging/#next-steps","title":"Next Steps","text":"<p>Now that you know how to visualize PDF content, you might want to explore:</p> <ul> <li>OCR capabilities for working with scanned documents</li> <li>Layout analysis for automatic structure detection</li> <li>Document QA for asking questions directly to your documents</li> </ul>"}]}